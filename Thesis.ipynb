{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core import Experiment,Workspace, Run\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.train.dnn import TensorFlow\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.widgets import RunDetails\n",
    "from collections import defaultdict\n",
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from PIL import Image, ImageFilter\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, Activation, Flatten, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from skimage import io as io\n",
    "from skimage import exposure\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import blob_dog, blob_log, blob_doh, corner_harris, corner_subpix, corner_peaks, daisy, hog\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "import traceback\n",
    "import timeit\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(azureml.core.VERSION)\n",
    "\n",
    "subscription_id = os.getenv(\"SUBSCRIPTION_ID\", default=\"9bce0414-e6b9-4c79-b146-74018a4b09ac\")\n",
    "resource_group = os.getenv(\"RESOURCE_GROUP\", default=\"Thesis\")\n",
    "workspace_name = os.getenv(\"WORKSPACE_NAME\", default=\"Multi-label_classification\")\n",
    "workspace_region = os.getenv(\"WORKSPACE_REGION\", default=\"eastus2\")\n",
    "try:\n",
    "    ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\n",
    "    # write the details of the workspace to a configuration file to the notebook library\n",
    "    ws.write_config()\n",
    "    print(\"Workspace configuration succeeded. Skip the workspace creation steps below\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"Workspace not accessible. Change your parameters or create a new workspace below\")\n",
    "    \n",
    "cpu_cluster_name = \"cpucluster\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print(\"Found existing cpucluster\")\n",
    "except ComputeTargetException:\n",
    "    print(\"Creating new cpucluster\")\n",
    "    \n",
    "    # Specify the configuration for the new cluster\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_D2_V2\",\n",
    "                                                           min_nodes=0,\n",
    "                                                           max_nodes=4)\n",
    "\n",
    "    # Create the cluster with the specified name and configuration\n",
    "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "    \n",
    "    # Wait for the cluster to complete, show the output log\n",
    "    cpu_cluster.wait_for_completion(show_output=True)\n",
    "\n",
    "gpu_cluster_name = \"gpucluster\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    gpu_cluster = ComputeTarget(workspace=ws, name=gpu_cluster_name)\n",
    "    print(\"Found existing gpu cluster\")\n",
    "except ComputeTargetException:\n",
    "    print(\"Creating new gpucluster\")\n",
    "    \n",
    "    # Specify the configuration for the new cluster\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_NC6\",\n",
    "                                                           min_nodes=0,\n",
    "                                                           max_nodes=4)\n",
    "    # Create the cluster with the specified name and configuration\n",
    "    gpu_cluster = ComputeTarget.create(ws, gpu_cluster_name, compute_config)\n",
    "\n",
    "    # Wait for the cluster to complete, show the output log\n",
    "    gpu_cluster.wait_for_completion(show_output=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "# Create the workspace using the specified parameters\n",
    "ws = Workspace.create(name = workspace_name,\n",
    "                      subscription_id = subscription_id,\n",
    "                      resource_group = resource_group, \n",
    "                      location = workspace_region,\n",
    "                      create_resource_group = True,\n",
    "                      exist_ok = True)\n",
    "ws.get_details()\n",
    "\n",
    "# write the details of the workspace to a configuration file to the notebook library\n",
    "ws.write_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'multi-class_classification'\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a name for your cluster\n",
    "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"cpucluster\")\n",
    "compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n",
    "compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 4)\n",
    "\n",
    "# This example uses CPU VM. For using GPU VM, set SKU to STANDARD_NC6\n",
    "vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"STANDARD_D2_V2\")\n",
    "\n",
    "\n",
    "if compute_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print('found compute target. just use it. ' + compute_name)\n",
    "else:\n",
    "    print('creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size,\n",
    "                                                                min_nodes = compute_min_nodes, \n",
    "                                                                max_nodes = compute_max_nodes)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
    "    \n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "     # For a more detailed view of current AmlCompute status, use get_status()\n",
    "    print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ws.get_default_datastore()\n",
    "print(ds.datastore_type, ds.account_name, ds.container_name)\n",
    "#ds.upload(src_dir='./data', target_path='data', overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_folder = './coco-multi-label'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/annotations/instances_train2014.json\") as read_file:\n",
    "    train = json.load(read_file)\n",
    "'''\n",
    "with open(\"data/annotations/instances_val2014.json\") as read_file:\n",
    "    val = json.load(read_file)\n",
    "with open(\"data/annotations/instances_train2014.json\") as read_file:\n",
    "    instances = json.load(read_file)\n",
    "with open(\"data/annotations/person_keypoints_train2014.json\") as read_file:\n",
    "    keypoints = json.load(read_file)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = train[\"categories\"]\n",
    "#print(categories)\n",
    "train_images = train[\"images\"]\n",
    "#val_images = val[\"images\"]\n",
    "print(\"Number of images in 2014 train: \"+str(len(train_images)))\n",
    "#print(\"Number of images in 2014 val: \"+str(len(val_images)) +\"\\n\")\n",
    "train_annotations = train[\"annotations\"]\n",
    "#print(train_annotations[1:20])\n",
    "#val_annotations = val[\"annotations\"]\n",
    "print(\"Number of annotations in 2014 train: \"+str(len(train_annotations)))\n",
    "#print(\"Number of annotations in 2014 val: \"+str(len(val_annotations)) + \"\\n\")\n",
    "print(\"Number of annotations/image in 2014 train: \"+str(len(train_annotations)/len(train_images)))\n",
    "#print(\"Number of annotations/image in 2014 val: \" + str(len(val_annotations)/len(val_images)) + \"\\n\")\n",
    "train_categories = np.zeros(100, dtype=object)\n",
    "#val_categories = np.zeros(100, dtype=object)\n",
    "#itemsets = [[] for i in range(581922)]\n",
    "itemsets = defaultdict(list)\n",
    "for annotation in train_annotations:\n",
    "    train_categories[annotation['category_id']] += 1\n",
    "    itemsets[annotation['image_id']].append(annotation['category_id'])\n",
    "unique_itemsets = []\n",
    "for entry in itemsets:\n",
    "    if(entry not in unique_itemsets):\n",
    "        unique_itemsets.append(entry)\n",
    "print(len(unique_itemsets))\n",
    "#for annotation in val_annotations:\n",
    "#    val_categories[annotation['category_id']] += 1\n",
    "train_categories = train_categories[train_categories != 0]\n",
    "#val_categories = val_categories[val_categories != 0]\n",
    "print(\"Label density in 2014 train: \"+str(len(train_annotations)/len(train_categories)/len(train_images)))\n",
    "#print(\"Label density in 2014 val: \"+str(len(val_annotations)/len(val_categories)/len(val_images)))\n",
    "print(train.keys())\n",
    "print(\"\\n\")\n",
    "#print(images[1:10])\n",
    "#print(\"\\n\")\n",
    "#print(annotations[1:10])\n",
    "#print(\"\\n\")\n",
    "#print(categories)\n",
    "for i in range(0, len(train_categories)):\n",
    "    print(str(categories[i][\"id\"]) + categories[i][\"name\"] + \": \" + str(train_categories[i]))\n",
    "    train_categories[i] = (categories[i][\"name\"], train_categories[i])\n",
    "#for i in range(0, len(val_categories)):\n",
    "    #print(categories[i][\"name\"] + \": \" + str(train_categories[i]))\n",
    "#    val_categories[i] = (categories[i][\"name\"], val_categories[i])\n",
    "plt.figure(1)\n",
    "plt.subplot(211)\n",
    "plt.plot([i[1] for i in train_categories])\n",
    "#plt.subplot(212)\n",
    "#plt.plot([i[1] for i in val_categories])\n",
    "plt.show()\n",
    "train_categories = sorted(train_categories, key=lambda tup: tup[1], reverse=False)\n",
    "#val_categories = sorted(val_categories, key=lambda tup: tup[1], reverse=False)\n",
    "print(\"\\n10 least used features \\n\")\n",
    "print(train_categories[0:9])\n",
    "print(\"\\n\")\n",
    "#print(val_categories[0:9])\n",
    "print(\"\\n10 most used features \\n\")\n",
    "print(train_categories[-10:])\n",
    "print(\"\\n\")\n",
    "#print(val_categories[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "# Get a sorted list of the objects and their sizes\n",
    "sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = 49 #9,25,30,34,36,49\n",
    "def findAnnotations(id, property):\n",
    "    items = []\n",
    "    for annotation in train_annotations: \n",
    "        if annotation[property] == id:\n",
    "            items.append(annotation)\n",
    "    return items\n",
    "items = findAnnotations(image_id, 'image_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findValueDictionary(dict,key,value, returnkey):\n",
    "    for entry in dict:\n",
    "        if entry[key] == value:\n",
    "            return entry[returnkey]\n",
    "\n",
    "image_id_string = str(image_id).zfill(12)\n",
    "image = np.array(Image.open('data/train2014/COCO_train2014_'+ image_id_string +'.jpg'), dtype=np.uint8)\n",
    "fig,ax = plt.subplots(1)\n",
    "ax.imshow(image)\n",
    "colors = np.random.random((len(categories)+10, 3))\n",
    "i=0\n",
    "bbox_list = []\n",
    "item_list = []\n",
    "for item in items:\n",
    "    label = findValueDictionary(categories, 'id', item['category_id'], 'name')\n",
    "    rect = patches.Rectangle((item['bbox'][0], (item['bbox'][1])), item['bbox'][2], item['bbox'][3],linewidth=1,edgecolor=colors[item['category_id']-1],facecolor='none', label= label)\n",
    "    ax.add_patch(rect)\n",
    "    bbox_list.append(rect)\n",
    "    item_list.append(item['category_id'])\n",
    "#print(items)\n",
    "plt.figure(figsize=(3,4))\n",
    "plt.legend(handles=bbox_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core import Run\n",
    "import cv2\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import os\n",
    "from PIL import Image, ImageFilter\n",
    "from skimage import io as io\n",
    "from skimage import exposure\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import blob_dog, blob_log, blob_doh, corner_harris, corner_subpix, corner_peaks, daisy, hog\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from time import time\n",
    "\n",
    "def loadAnnotations(fileLocation):\n",
    "    with open(fileLocation) as read_file:\n",
    "        annotations = json.load(read_file)\n",
    "    return annotations\n",
    "    \n",
    "def getBoundingBox(x,y,w,h,img):\n",
    "    return img[y:y+h,x:x+w]\n",
    "\n",
    "def findAnnotations(id, property, annotations):\n",
    "    items = []\n",
    "    for annotation in annotations: \n",
    "        if annotation[property] == id:\n",
    "            items.append(annotation)\n",
    "    return items\n",
    "\n",
    "def zca_whitening_matrix(X):\n",
    "    # Covariance matrix [column-wise variables]: Sigma = (X-mu)' * (X-mu) / N\n",
    "    sigma = np.cov(X, rowvar=True) # [M x M]\n",
    "    # Singular Value Decomposition. X = U * np.diag(S) * V\n",
    "    U,S,V = np.linalg.svd(sigma)\n",
    "        # U: [M x M] eigenvectors of sigma.\n",
    "        # S: [M x 1] eigenvalues of sigma.\n",
    "        # V: [M x M] transpose of U\n",
    "    # Whitening constant: prevents division by zero\n",
    "    epsilon = 1e-5\n",
    "    # ZCA Whitening matrix: U * Lambda * U'\n",
    "    ZCAMatrix = np.dot(U, np.dot(np.diag(1.0/np.sqrt(S + epsilon)), U.T)) # [M x M]\n",
    "    return ZCAMatrix\n",
    "\n",
    "def preProcessImage(img):\n",
    "    img = np.asarray(img)\n",
    "    img = rgb2gray(img)\n",
    "    #img = cv2.GaussianBlur(img,(5,5),0)\n",
    "    #img = cv2.medianBlur(img,5)\n",
    "    #img = cv2.bilateralFilter(img,9,75,75)\n",
    "    #img = cv2.blur(img,(5,5))\n",
    "    #kernel = np.ones((5,5),np.float32)/25\n",
    "    #img = cv2.filter2D(img,-1,kernel)\n",
    "    return img\n",
    "\n",
    "def getBoundingBoxesPictures(annotations, path):\n",
    "    bounded_images = []\n",
    "    bounded_annotations = []\n",
    "    try:\n",
    "        for annotation in annotations:\n",
    "            image_id = annotation['image_id']\n",
    "            image_id_string = str(image_id).zfill(12)\n",
    "            image = Image.open(path + image_id_string +'.jpg')\n",
    "            image = preProcessImage(image) \n",
    "            image_resized = resize(getBoundingBox(int(annotation['bbox'][0]),int(annotation['bbox'][1]),int(annotation['bbox'][2]),int(annotation['bbox'][3]),image)\n",
    "                                   , (64, 64),\n",
    "                           anti_aliasing=True)\n",
    "            bounded_images.append(image_resized)\n",
    "            bounded_annotations.append(annotation['category_id'])     \n",
    "    except Exception as ex:\n",
    "            print(ex)   \n",
    "    bounded_images = np.asarray(bounded_images)\n",
    "    bounded_annotations = np.asarray(bounded_annotations)\n",
    "    return bounded_images,bounded_annotations\n",
    "\n",
    "def calculateHogFeatures(gray_image, o, pixels, cells):\n",
    "    features = hog(gray_image, orientations=o, \n",
    "                              pixels_per_cell=(pixels, pixels),\n",
    "                              cells_per_block=(cells, cells), \n",
    "                              transform_sqrt=True, \n",
    "                              visualize=False, block_norm = \"L2-Hys\")\n",
    "    return features\n",
    "def calculateDaisyFeatures(gray_image):\n",
    "    descs = daisy(gray_image, step=180, radius=15, rings=3, histograms=6,\n",
    "                         orientations=8, visualize=False)\n",
    "    descs_num = descs.shape[0] * descs.shape[1]\n",
    "    return descs.reshape(descs.size).tolist()\n",
    "\n",
    "def calculateDoG(gray_image):\n",
    "    blobs_dog = blob_dog(gray_img, max_sigma=30, threshold=.1)\n",
    "    blobs_dog[:, 2] = blobs_dog[:, 2] * sqrt(2)\n",
    "    return blobs_dog\n",
    "\n",
    "def calculateSIFT(sift, gray_image):\n",
    "    kp = sift.detect(gray_image,None)\n",
    "    return kp\n",
    "\n",
    "def calculateFeatures(imgs):\n",
    "    #sift = cv2.xfeatures2d.SIFT_create()\n",
    "    hog_features = []\n",
    "    dog_features = []\n",
    "    daisy_features = []\n",
    "    sift_features = []\n",
    "    i = 0;\n",
    "    for img in imgs:\n",
    "        hog_features.append(calculateHogFeatures(img,8,16,1))\n",
    "        #dog_features.append(calculateDoG(img))\n",
    "        #sift_features.append(calculateSIFT(sift, img))\n",
    "        daisy_features.append(calculateDaisyFeatures(img))\n",
    "    return hog_features, daisy_features\n",
    "\n",
    "def svmFit(x_train, y_train):\n",
    "    print(\"Fitting the classifier to train\")\n",
    "    t0 = time()\n",
    "    param_grid = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "                  'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], }\n",
    "    clf = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'),\n",
    "                       param_grid, cv=5)\n",
    "    clf = clf.fit(x_train, y_train)\n",
    "    print(\"Completed in %0.3fs\" % (time() - t0))\n",
    "    print(\"Best estimator found by grid search:\")\n",
    "    print(clf.best_estimator_)\n",
    "    return clf\n",
    "\n",
    "def saveModel(model, filename):\n",
    "    print(\"Saving file...\")\n",
    "    joblib.dump(model, open(filename, 'wb'))\n",
    "    print(\"File saved\")\n",
    "    \n",
    "def loadModel(filename):\n",
    "    print(\"loading file...\")\n",
    "    joblib.load(filename)\n",
    "    print(\"Model loaded\")\n",
    "    \n",
    "def svmPredict(x_test, y_test, model):\n",
    "    print(\"Predicting the test set\")\n",
    "    t0 = time()\n",
    "    y_pred = model.predict(x_test)\n",
    "    print(\"Completed in %0.3fs\" % (time() - t0))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "def randomForestFit(x_train, y_train, estimators):\n",
    "    print(\"Fitting the classifier to train\")\n",
    "    t0 = time()\n",
    "    rf = RandomForestClassifier(n_estimators=estimators)\n",
    "    rf.fit(x_train, y_train);\n",
    "    print(\"Completed in %0.3fs\" % (time() - t0))\n",
    "    return rf\n",
    "\n",
    "def rfPredict(x_test, y_test, model):\n",
    "    print(\"Predicting the test set\")\n",
    "    t0 = time()\n",
    "    y_pred = model.predict(x_test)\n",
    "    print(\"Completed in %0.3fs\" % (time() - t0))\n",
    "    errors = abs(y_pred - y_test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "  \n",
    "def constructCNN(conv_layer, layer_size, dense_layer, kernel_size, dropout, num_classes):\n",
    "    NAME = \"{}-conv-{}-nodes-{}-dense-{}-kernel-{}\".format(conv_layer, layer_size, dense_layer, kernel_size, int(time()))\n",
    "    print(NAME)\n",
    "    early_stopping_monitor = EarlyStopping(patience = 4)\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(layer_size, (kernel_size, kernel_size), input_shape=trainset.shape[1:]))\n",
    "\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    for l in range(conv_layer-1):\n",
    "        model.add(Conv2D(layer_size, (kernel_size, kernel_size)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    if(dropout):\n",
    "        model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    for j in range(dense_layer):\n",
    "        model.add(Dense(layer_size))\n",
    "        model.add(Activation('relu'))\n",
    "    if(dropout):\n",
    "        model.add(Dropout(0.25))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "    \n",
    "# Create a function called \"chunks\" with two arguments, l and n:\n",
    "def chunks(l, n):\n",
    "    # For item i in a range that is a length of l,\n",
    "    for i in range(0, len(l), n):\n",
    "        # Create an index range for l of n items:\n",
    "        yield l[i:i+n]\n",
    "\n",
    "def splitPreprocessing(splits, data_folder, path):\n",
    "    labels = []\n",
    "    features = np.asarray([[],[]])\n",
    "    for split in splits:\n",
    "        bboxes = getBoundingBoxesPictures(split, os.path.join(data_folder, path))\n",
    "        splitfeatures = calculateFeatures(bboxes[0])\n",
    "        features = np.append(features, splitfeatures,1)\n",
    "        labels.extend(bboxes[1])\n",
    "    return labels, features.tolist()\n",
    "\n",
    "data_folder = 'data'\n",
    "\n",
    "path = \"train2014/COCO_train2014_\"\n",
    "valpath = \"val2014/val2014/COCO_val2014_\"\n",
    "category = \"category_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "train_annotations = loadAnnotations(os.path.join(data_folder, 'annotations/instances_train2014.json'))\n",
    "train_annotations = train_annotations[\"annotations\"]\n",
    "\n",
    "val_annotations = loadAnnotations(os.path.join(data_folder, 'annotations/instances_val2014.json'))\n",
    "val_annotations = val_annotations[\"annotations\"]\n",
    "'''\n",
    "'''\n",
    "#testsplits = list(chunks(dummy_annotations, 50))\n",
    "#labels, features = splitPreprocessing(testsplits, data_folder, path)\n",
    "\n",
    "'''\n",
    "categories_subset = [2,4]\n",
    "bbox = getBoundingBoxesPictures(findAnnotations(categories_subset[0], category, train_annotations),  os.path.join(data_folder, path))\n",
    "imgs = bbox[0]\n",
    "categories_subset.pop(0)\n",
    "labels = bbox[1]\n",
    "for category_id in categories_subset:\n",
    "    bbox = getBoundingBoxesPictures(findAnnotations(category_id, category, train_annotations),  os.path.join(data_folder, path))\n",
    "    imgs = np.concatenate((imgs,bbox[0]))\n",
    "    labels = np.concatenate((labels,bbox[1]))\n",
    "features = calculateFeatures(imgs)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    features[0], labels, test_size=0.25, random_state=42)\n",
    "svmHOG = svmFit(x_train, y_train)\n",
    "\n",
    "svmHOGResults = svmPredict(x_test, y_test, svmHOG)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    features[1], labels, test_size=0.25, random_state=42)\n",
    "svmDaisy = svmFit(x_train, y_train)\n",
    "svmDaisyResults = svmPredict(x_test, y_test, svmDaisy)\n",
    "#saveModel(svm, 'SVM_DAISY.sav')\n",
    "os.makedirs('outputs', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "categories_subset = [2,4]#[2,4,5,6,7]\n",
    "bbox = getBoundingBoxesPictures(findAnnotations(categories_subset[0], category, train_annotations),  os.path.join(data_folder, path))\n",
    "imgs = bbox[0]\n",
    "categories_subset.pop(0)\n",
    "labels = bbox[1]\n",
    "for category_id in categories_subset:\n",
    "    bbox = getBoundingBoxesPictures(findAnnotations(category_id, category, train_annotations),  os.path.join(data_folder, path))\n",
    "    imgs = np.concatenate((imgs,bbox[0]))\n",
    "    labels = np.concatenate((labels,bbox[1]))\n",
    "features = calculateFeatures(imgs)\n",
    "'''\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    features[0], labels, test_size=0.25, random_state=42)\n",
    "rfHOG = randomForestFit(x_train, y_train, 100)\n",
    "rfHOG_results = rfPredict(x_test, y_test, rfHOG)\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    features[1], labels, test_size=0.25, random_state=42)\n",
    "rfDaisy = randomForestFit(x_train, y_train, 100)\n",
    "rfDaisy_results = rfPredict(x_test, y_test, rfDaisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# width 578.2023976316078\n",
    "# heigth 483.5494085111049\n",
    "\n",
    "path = \"data/train2014/COCO_train2014_\"\n",
    "def getPictures(itemsets, path, instance):\n",
    "    images = []\n",
    "    image_ids = []\n",
    "    image_tags = []\n",
    "    avg_width, avg_height = (0,0)\n",
    "    try:\n",
    "        for itemset in itemsets:\n",
    "            print(itemset)\n",
    "            print(itemsets[itemset])\n",
    "            if(instance in itemsets[itemset]):\n",
    "                image_id_string = str(itemset).zfill(12)\n",
    "                image_ids.append(str(itemset))\n",
    "                image = Image.open(path + image_id_string +'.jpg')\n",
    "                processed_img = preProcessImage(image)\n",
    "                image.close()\n",
    "                resized_image = resize(processed_img, (350, 292),anti_aliasing=True)\n",
    "                images.append(resized_image)\n",
    "                image_tags.append(itemsets[itemset])\n",
    "    except Exception as ex:\n",
    "            print(ex)   \n",
    "    return image_ids,images,image_tags\n",
    "\n",
    "pictureData = getPictures(itemsets, path, 18)\n",
    "#print(pictureData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "dummy_annotations = np.concatenate((findAnnotations(87, category, train_annotations),findAnnotations(89, category, train_annotations)))\n",
    "bbox = getBoundingBoxesPictures(dummy_annotations, os.path.join(data_folder, path))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    bbox[0], bbox[1], test_size=0.25, random_state=42)\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "from keras.datasets import mnist\n",
    "(mnist_train, y_minst_train), (mnist_test, y_minst_test) = mnist.load_data()\n",
    "\n",
    "categories_subset = [2,4,5,6]\n",
    "bbox = getBoundingBoxesPictures(findAnnotations(categories_subset[0], category, train_annotations),  os.path.join(data_folder, path))\n",
    "imgs = bbox[0]\n",
    "categories_subset.pop(0)\n",
    "labels = bbox[1]\n",
    "for category_id in categories_subset:\n",
    "    bbox = getBoundingBoxesPictures(findAnnotations(category_id, category, train_annotations),  os.path.join(data_folder, path))\n",
    "    imgs = np.concatenate((imgs,bbox[0]))\n",
    "    labels = np.concatenate((labels,bbox[1]))\n",
    "\n",
    "#images = np.asarray(pictureData[1])\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    imgs, labels, test_size=0.25, random_state=42)\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "\n",
    "for (i,value) in enumerate(y_train):\n",
    "    if value == 2:\n",
    "        y_train[i] = 0\n",
    "    if value == 4:\n",
    "        y_train[i] = 1\n",
    "    if value == 5:\n",
    "        y_train[i] = 2\n",
    "    if value == 6:\n",
    "        y_train[i] = 3\n",
    "for (i,value) in enumerate(y_test):\n",
    "    if value == 2:\n",
    "         y_test[i] = 0\n",
    "    if value == 4:\n",
    "         y_test[i] = 1\n",
    "    if value == 5:\n",
    "         y_test[i] = 2\n",
    "    if value == 6:\n",
    "         y_test[i] = 2\n",
    "\n",
    "trainset = np.expand_dims(x_train, axis=len(x_train.shape))\n",
    "\n",
    "whitened_images = []\n",
    "for image in x_train:\n",
    "    whitened_images.append(zca_whitening_matrix(image))\n",
    "whitened_images = np.asarray(whitened_images)\n",
    "whitened_images = np.expand_dims(whitened_images, axis=3)\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    zca_whitening=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "#datagen.fit(trainset)\n",
    "'''\n",
    "sess = tf.Session()\n",
    "'''\n",
    "dense_layers = [0, 1, 2]\n",
    "layer_sizes = [32, 64, 128]\n",
    "conv_layers = [1, 2, 3]\n",
    "'''\n",
    "dense_layers = [1]\n",
    "layer_sizes = [64]\n",
    "conv_layers = [3]\n",
    "kernel_sizes = [3,4]\n",
    "y_categorical = to_categorical(y_train)\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            for kernel_size in kernel_sizes:\n",
    "                model = constructCNN(conv_layer, layer_size, dense_layer, kernel_size, True, 4)\n",
    "                model.fit(trainset.astype(np.float32), y_categorical, batch_size=70, epochs=20, validation_split=0.1, callbacks = [tensorboard])\n",
    "'''\n",
    "\n",
    "\n",
    "print(trainset.shape)\n",
    "print(y_train.shape)\n",
    "mnist_train = np.expand_dims(mnist_train, axis=len(mnist_train.shape))\n",
    "ylabels_train = to_categorical(y_train)\n",
    "#hot_encoded = tf.one_hot(y_train, 4)\n",
    "#model.fit_generator(datagen.flow(trainset, y_train, batch_size=70), epochs=15)\n",
    "model.fit(trainset, y_train, batch_size=70, epochs=5, validation_split=0.1, callbacks = [tensorboard])\n",
    "'''\n",
    "#model.evaluate(augmented_x_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x_train[0])\n",
    "print(y_train[0:30])\n",
    "fig,ax = plt.subplots(1)\n",
    "ax.imshow(x_train[14], cmap='gray')\n",
    "print(augmented_x_train.shape)\n",
    "print(mnist_train.shape)\n",
    "print(trainset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $script_folder/train.py\n",
    "\n",
    "import argparse\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core import Run\n",
    "\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import os\n",
    "from PIL import Image, ImageFilter\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import blob_dog, blob_log, blob_doh, corner_harris, corner_subpix, corner_peaks, daisy, hog\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "import time\n",
    "\n",
    "def loadAnnotations(fileLocation):\n",
    "    with open(fileLocation) as read_file:\n",
    "        annotations = json.load(read_file)\n",
    "    return annotations\n",
    "    \n",
    "def getBoundingBox(x,y,w,h,img):\n",
    "    return img[y:y+h,x:x+w]\n",
    "\n",
    "def findAnnotations(id, property, annotations):\n",
    "    items = []\n",
    "    for annotation in annotations: \n",
    "        if annotation[property] == id:\n",
    "            items.append(annotation)\n",
    "    return items\n",
    "\n",
    "def zca_whitening_matrix(X):\n",
    "    # Covariance matrix [column-wise variables]: Sigma = (X-mu)' * (X-mu) / N\n",
    "    sigma = np.cov(X, rowvar=True) # [M x M]\n",
    "    # Singular Value Decomposition. X = U * np.diag(S) * V\n",
    "    U,S,V = np.linalg.svd(sigma)\n",
    "        # U: [M x M] eigenvectors of sigma.\n",
    "        # S: [M x 1] eigenvalues of sigma.\n",
    "        # V: [M x M] transpose of U\n",
    "    # Whitening constant: prevents division by zero\n",
    "    epsilon = 1e-5\n",
    "    # ZCA Whitening matrix: U * Lambda * U'\n",
    "    ZCAMatrix = np.dot(U, np.dot(np.diag(1.0/np.sqrt(S + epsilon)), U.T)) # [M x M]\n",
    "    return ZCAMatrix\n",
    "\n",
    "def preProcessImage(img):\n",
    "    img = np.asarray(img)\n",
    "    img = rgb2gray(img)\n",
    "    #img = cv2.GaussianBlur(img,(5,5),0)\n",
    "    #img = cv2.medianBlur(img,5)\n",
    "    #img = cv2.bilateralFilter(img,9,75,75)\n",
    "    #img = cv2.blur(img,(5,5))\n",
    "    #kernel = np.ones((5,5),np.float32)/25\n",
    "    #img = cv2.filter2D(img,-1,kernel)\n",
    "    return img\n",
    "\n",
    "def getBoundingBoxesPictures(annotations, path):\n",
    "    bounded_images = []\n",
    "    bounded_annotations = []\n",
    "    try:\n",
    "        for annotation in annotations:\n",
    "            image_id = annotation['image_id']\n",
    "            image_id_string = str(image_id).zfill(12)\n",
    "            image = Image.open(path + image_id_string +'.jpg')\n",
    "            image = preProcessImage(image) \n",
    "            image_resized = resize(getBoundingBox(int(annotation['bbox'][0]),int(annotation['bbox'][1]),int(annotation['bbox'][2]),int(annotation['bbox'][3]),image)\n",
    "                                   , (64, 64),\n",
    "                           anti_aliasing=True)\n",
    "            bounded_images.append(image_resized)\n",
    "            bounded_annotations.append(annotation['category_id'])     \n",
    "    except Exception as ex:\n",
    "            print(ex)   \n",
    "    bounded_images = np.asarray(bounded_images)\n",
    "    bounded_annotations = np.asarray(bounded_annotations)\n",
    "    return bounded_images,bounded_annotations\n",
    "\n",
    "def calculateHogFeatures(gray_image, o, pixels, cells):\n",
    "    features = hog(gray_image, orientations=o, \n",
    "                              pixels_per_cell=(pixels, pixels),\n",
    "                              cells_per_block=(cells, cells), \n",
    "                              transform_sqrt=True, \n",
    "                              visualize=False, block_norm = \"L2-Hys\")\n",
    "    return features\n",
    "def calculateDaisyFeatures(gray_image):\n",
    "    descs = daisy(gray_image, step=180, radius=15, rings=3, histograms=6,\n",
    "                         orientations=8, visualize=False)\n",
    "    descs_num = descs.shape[0] * descs.shape[1]\n",
    "    return descs.reshape(descs.size).tolist()\n",
    "\n",
    "def calculateDoG(gray_image):\n",
    "    blobs_dog = blob_dog(gray_img, max_sigma=30, threshold=.1)\n",
    "    blobs_dog[:, 2] = blobs_dog[:, 2] * sqrt(2)\n",
    "    return blobs_dog\n",
    "\n",
    "def calculateSIFT(sift, gray_image):\n",
    "    kp = sift.detect(gray_image,None)\n",
    "    return kp\n",
    "\n",
    "def calculateFeatures(imgs):\n",
    "    #sift = cv2.xfeatures2d.SIFT_create()\n",
    "    hog_features = []\n",
    "    dog_features = []\n",
    "    daisy_features = []\n",
    "    sift_features = []\n",
    "    i = 0;\n",
    "    for img in imgs:\n",
    "        hog_features.append(calculateHogFeatures(img,8,16,1))\n",
    "        #dog_features.append(calculateDoG(img))\n",
    "        #sift_features.append(calculateSIFT(sift, img))\n",
    "        daisy_features.append(calculateDaisyFeatures(img))\n",
    "    return hog_features, daisy_features\n",
    "\n",
    "def svmFit(x_train, y_train):\n",
    "    print(\"Fitting the classifier to train\")\n",
    "    t0 = time.time()\n",
    "    param_grid = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "                  'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], }\n",
    "    clf = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'),\n",
    "                       param_grid, cv=5)\n",
    "    clf = clf.fit(x_train, y_train)\n",
    "    print(\"Completed in %0.3fs\" % (time.time() - t0))\n",
    "    print(\"Best estimator found by grid search:\")\n",
    "    print(clf.best_estimator_)\n",
    "    return clf\n",
    "\n",
    "def saveModel(model, filename):\n",
    "    print(\"Saving file...\")\n",
    "    joblib.dump(model, open(filename, 'wb'))\n",
    "    print(\"File saved\")\n",
    "    \n",
    "def loadModel(filename):\n",
    "    print(\"loading file...\")\n",
    "    joblib.load(filename)\n",
    "    print(\"Model loaded\")\n",
    "    \n",
    "def svmPredict(x_test, y_test, model):\n",
    "    print(\"Predicting the test set\")\n",
    "    t0 = time.time()\n",
    "    y_pred = model.predict(x_test)\n",
    "    print(\"Completed in %0.3fs\" % (time.time() - t0))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "def randomForestFit(x_train, y_train, estimators, random_state):\n",
    "    print(\"Fitting the classifier to train\")\n",
    "    t0 = time.time()\n",
    "    rf = RandomForestRegressor(n_estimators = estimators, random_state = random_state)\n",
    "    rf.fit(x_train, y_train);\n",
    "    print(\"Completed in %0.3fs\" % (time.time() - t0))\n",
    "    return rf\n",
    "\n",
    "def rfPredict(x_test, y_test, model):\n",
    "    print(\"Predicting the test set\")\n",
    "    t0 = time.time()\n",
    "    y_pred = model.predict(x_test)\n",
    "    print(\"Completed in %0.3fs\" % (time.time() - t0))\n",
    "    errors = abs(y_pred - y_test)\n",
    "    print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "    # Calculate mean absolute percentage error (MAPE)\n",
    "    mape = 100 * (errors / y_test)\n",
    "    # Calculate and display accuracy\n",
    "    accuracy = 100 - np.mean(mape)\n",
    "    print('Accuracy:', round(accuracy, 2), '%.')\n",
    "    \n",
    "    \n",
    "# Create a function called \"chunks\" with two arguments, l and n:\n",
    "def chunks(l, n):\n",
    "    # For item i in a range that is a length of l,\n",
    "    for i in range(0, len(l), n):\n",
    "        # Create an index range for l of n items:\n",
    "        yield l[i:i+n]\n",
    "\n",
    "def splitPreprocessing(splits, data_folder, path):\n",
    "    labels = []\n",
    "    features = np.asarray([[],[]])\n",
    "    for split in splits:\n",
    "        bboxes = getBoundingBoxesPictures(split, os.path.join(data_folder, path))\n",
    "        splitfeatures = calculateFeatures(bboxes[0])\n",
    "        features = np.append(features, splitfeatures,1)\n",
    "        labels.extend(bboxes[1])\n",
    "    return labels, features.tolist()\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data-folder', type=str, dest='data_folder', help='data folder mounting point')\n",
    "args = parser.parse_args()\n",
    "data_folder = os.path.join(args.data_folder, 'data')\n",
    "print('Data folder:', data_folder)\n",
    "run = Run.get_context()\n",
    "\n",
    "path = \"train2014/COCO_train2014_\"\n",
    "category = \"category_id\"\n",
    "train_annotations = loadAnnotations(os.path.join(data_folder, 'annotations/instances_train2014.json'))\n",
    "train_annotations = train_annotations[\"annotations\"]\n",
    "'''\n",
    "dummy_annotations = np.concatenate((findAnnotations(87, category, train_annotations),findAnnotations(89, category, train_annotations)))\n",
    "bbox_train = getBoundingBoxesPictures(dummy_annotations, os.path.join(data_folder, path))\n",
    "\n",
    "'''\n",
    "categories_subset = [2,4,5,6]\n",
    "bbox = getBoundingBoxesPictures(findAnnotations(categories_subset[0], category, train_annotations),  os.path.join(data_folder, path))\n",
    "imgs = bbox[0]\n",
    "categories_subset.pop(0)\n",
    "labels = bbox[1]\n",
    "for category_id in categories_subset:\n",
    "    bbox = getBoundingBoxesPictures(findAnnotations(category_id, category, train_annotations),  os.path.join(data_folder, path))\n",
    "    imgs = np.concatenate((imgs,bbox[0]))\n",
    "    labels = np.concatenate((labels,bbox[1]))\n",
    "features = calculateFeatures(imgs)\n",
    "\n",
    "#splits = list(chunks(train_annotations, 20000))\n",
    "#labels, features = splitPreprocessing(splits, data_folder, path)\n",
    "print(\"[2,4,5,6]\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    features[0], labels, test_size=0.25, random_state=42)\n",
    "print(\"HOG\")\n",
    "svm = svmFit(x_train, y_train)\n",
    "#saveModel(svm, 'SVM_DAISY.sav')\n",
    "run.log('prediction', svmPredict(x_test, y_test, svm))\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "joblib.dump(value=svm, filename='outputs/SVM.pkl')\n",
    "joblib.dump(value=features, filename='outputs/features.npy')\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    features[1], labels, test_size=0.25, random_state=42)\n",
    "print(\"DAISY\")\n",
    "svm = svmFit(x_train, y_train)\n",
    "#saveModel(svm, 'SVM_DAISY.sav')\n",
    "run.log('prediction', svmPredict(x_test, y_test, svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $script_folder/neural_network.py\n",
    "\n",
    "import argparse\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core import Run\n",
    "\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import os\n",
    "from PIL import Image, ImageFilter\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import blob_dog, blob_log, blob_doh, corner_harris, corner_subpix, corner_peaks, daisy, hog\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "def loadAnnotations(fileLocation):\n",
    "    with open(fileLocation) as read_file:\n",
    "        annotations = json.load(read_file)\n",
    "    return annotations\n",
    "    \n",
    "def getBoundingBox(x,y,w,h,img):\n",
    "    return img[y:y+h,x:x+w]\n",
    "\n",
    "def findAnnotations(id, property, annotations):\n",
    "    items = []\n",
    "    for annotation in annotations: \n",
    "        if annotation[property] == id:\n",
    "            items.append(annotation)\n",
    "    return items\n",
    "\n",
    "def zca_whitening_matrix(X):\n",
    "    # Covariance matrix [column-wise variables]: Sigma = (X-mu)' * (X-mu) / N\n",
    "    sigma = np.cov(X, rowvar=True) # [M x M]\n",
    "    # Singular Value Decomposition. X = U * np.diag(S) * V\n",
    "    U,S,V = np.linalg.svd(sigma)\n",
    "        # U: [M x M] eigenvectors of sigma.\n",
    "        # S: [M x 1] eigenvalues of sigma.\n",
    "        # V: [M x M] transpose of U\n",
    "    # Whitening constant: prevents division by zero\n",
    "    epsilon = 1e-5\n",
    "    # ZCA Whitening matrix: U * Lambda * U'\n",
    "    ZCAMatrix = np.dot(U, np.dot(np.diag(1.0/np.sqrt(S + epsilon)), U.T)) # [M x M]\n",
    "    return ZCAMatrix\n",
    "\n",
    "def preProcessImage(img):\n",
    "    img = np.asarray(img)\n",
    "    img = rgb2gray(img)\n",
    "    #img = cv2.GaussianBlur(img,(5,5),0)\n",
    "    #img = cv2.medianBlur(img,5)\n",
    "    #img = cv2.bilateralFilter(img,9,75,75)\n",
    "    #img = cv2.blur(img,(5,5))\n",
    "    #kernel = np.ones((5,5),np.float32)/25\n",
    "    #img = cv2.filter2D(img,-1,kernel)\n",
    "    return img\n",
    "\n",
    "def getBoundingBoxesPictures(annotations, path):\n",
    "    bounded_images = []\n",
    "    bounded_annotations = []\n",
    "    try:\n",
    "        for annotation in annotations:\n",
    "            image_id = annotation['image_id']\n",
    "            image_id_string = str(image_id).zfill(12)\n",
    "            image = Image.open(path + image_id_string +'.jpg')\n",
    "            image = preProcessImage(image) \n",
    "            image_resized = resize(getBoundingBox(int(annotation['bbox'][0]),int(annotation['bbox'][1]),int(annotation['bbox'][2]),int(annotation['bbox'][3]),image)\n",
    "                                   , (64, 64),\n",
    "                           anti_aliasing=True)\n",
    "            bounded_images.append(image_resized)\n",
    "            bounded_annotations.append(annotation['category_id'])     \n",
    "    except Exception as ex:\n",
    "            print(ex)   \n",
    "    bounded_images = np.asarray(bounded_images)\n",
    "    bounded_annotations = np.asarray(bounded_annotations)\n",
    "    return bounded_images,bounded_annotations\n",
    "\n",
    "def saveModel(model, filename):\n",
    "    print(\"Saving file...\")\n",
    "    joblib.dump(model, open(filename, 'wb'))\n",
    "    print(\"File saved\")\n",
    "    \n",
    "def loadModel(filename):\n",
    "    print(\"loading file...\")\n",
    "    joblib.load(filename)\n",
    "    print(\"Model loaded\")\n",
    "    \n",
    "def cnn_model_fn(features, labels, mode):\n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    # Input Layer\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 64, 64, 1])\n",
    "\n",
    "    # Convolutional Layer #1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer #1\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "    # Convolutional Layer #2 and Pooling Layer #2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "    # Dense Layer\n",
    "    pool2_flat = tf.reshape(pool2, [-1, 16 * 16 * 64])\n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "    dropout = tf.layers.dropout(inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    # Logits Layer\n",
    "    logits = tf.layers.dense(inputs=dropout, units=90)\n",
    "    predictions = {\n",
    "        # Generate predictions (for PREDICT and EVAL mode)\n",
    "        \"classes\": tf.argmax(input=logits, axis=1),\n",
    "        # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "        # `logging_hook`.\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "    \n",
    "# Create a function called \"chunks\" with two arguments, l and n:\n",
    "def chunks(l, n):\n",
    "    # For item i in a range that is a length of l,\n",
    "    for i in range(0, len(l), n):\n",
    "        # Create an index range for l of n items:\n",
    "        yield l[i:i+n]\n",
    "\n",
    "def splitPreprocessing(splits, data_folder, path):\n",
    "    labels = []\n",
    "    features = np.asarray([[],[]])\n",
    "    for split in splits:\n",
    "        bboxes = getBoundingBoxesPictures(split, os.path.join(data_folder, path))\n",
    "        splitfeatures = calculateFeatures(bboxes[0])\n",
    "        features = np.append(features, splitfeatures,1)\n",
    "        labels.extend(bboxes[1])\n",
    "    return labels, features.tolist()\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data-folder', type=str, dest='data_folder', help='data folder mounting point')\n",
    "args = parser.parse_args()\n",
    "data_folder = os.path.join(args.data_folder, 'data')\n",
    "print('Data folder:', data_folder)\n",
    "run = Run.get_context()\n",
    "\n",
    "path = \"train2014/COCO_train2014_\"\n",
    "category = \"category_id\"\n",
    "train_annotations = loadAnnotations(os.path.join(data_folder, 'annotations/instances_train2014.json'))\n",
    "train_annotations = train_annotations[\"annotations\"]\n",
    "\n",
    "categories_subset = [2,4,5,6,7]\n",
    "bbox = getBoundingBoxesPictures(findAnnotations(categories_subset[0], category, train_annotations),  os.path.join(data_folder, path))\n",
    "imgs = bbox[0]\n",
    "categories_subset.pop(0)\n",
    "labels = bbox[1]\n",
    "for category_id in categories_subset:\n",
    "    bbox = getBoundingBoxesPictures(findAnnotations(category_id, category, train_annotations),  os.path.join(data_folder, path))\n",
    "    imgs = np.concatenate((imgs,bbox[0]))\n",
    "    labels = np.concatenate((labels,bbox[1]))\n",
    "\n",
    "#images = np.asarray(pictureData[1])\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    imgs, labels, test_size=0.25, random_state=42)\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "\n",
    "coco_classifier = tf.estimator.Estimator(\n",
    "    model_fn=cnn_model_fn, model_dir=\"/tmp/coco_convnet_model\")\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "    tensors=tensors_to_log, every_n_iter=50)\n",
    "# Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": x_train},\n",
    "    y=y_train,\n",
    "    batch_size=200,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\n",
    "# train one step and display the probabilties\n",
    "coco_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=1,\n",
    "    hooks=[logging_hook])\n",
    "coco_classifier.train(input_fn=train_input_fn, steps=20000)#1000 steps default\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": x_test},\n",
    "    y=y_test,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_results = coco_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)\n",
    "run.log('eval_results', eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.copy('utils.py', script_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "\n",
    "script_params = {\n",
    "    '--data-folder': ds.as_mount(),\n",
    "}\n",
    "\n",
    "\n",
    "est = Estimator(source_directory=script_folder,\n",
    "                script_params=script_params,\n",
    "                compute_target=compute_target,\n",
    "                entry_script='train.py',\n",
    "                conda_packages=['scikit-learn', 'scikit-image', 'pillow', 'opencv', 'numpy'])\n",
    "\n",
    "run = exp.submit(config=est)\n",
    "run\n",
    "'''\n",
    "\n",
    "keras_est = TensorFlow(source_directory=script_folder,\n",
    "                       script_params=script_params,\n",
    "                       compute_target=compute_target,\n",
    "                       entry_script='neural_network.py',\n",
    "                       pip_packages=['keras', 'scikit-learn', 'scikit-image', 'pillow'])\n",
    "\n",
    "run = exp.submit(config=keras_est)\n",
    "run\n",
    "'''\n",
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()\n",
    "\n",
    "run.wait_for_completion(show_output=True) # specify True for a verbose log\n",
    "\n",
    "print(run.get_metrics())\n",
    "\n",
    "print(run.get_file_names())\n",
    "\n",
    "# register model \n",
    "model = run.register_model(model_name='svm_hog', model_path='outputs/svm_hog.pkl')\n",
    "print(model.name, model.id, model.version, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in exp.get_runs():  \n",
    "    print(r.id, r.get_status())\n",
    "    if r.get_status() not in ['Complete', 'Failed']:\n",
    "        r.cancel()\n",
    "\n",
    "# if you know the run id, you can \"rehydrate\" the run\n",
    "from azureml.core import get_run\n",
    "#r = get_run(experiment=exp, run_id=\"multi-class_classification_1552234551_7c1e71ae\", rehydrate=True)\n",
    "# check the returned run type and status\n",
    "print(type(r), r.get_status())\n",
    "\n",
    "# you can cancel a run if it hasn't completed or failed\n",
    "#if r.get_status() not in ['Complete', 'Failed']:\n",
    "    #r.cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gray_img = rgb2gray(image)\n",
    "color = ('b','g','r')\n",
    "plt.figure()\n",
    "for i,col in enumerate(color):\n",
    "    histr = cv2.calcHist([image],[i],None,[256],[0,256])\n",
    "    plt.plot(histr,color = col)\n",
    "    plt.xlim([0,256])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()\n",
    "#print(x_train[0:9].values)\n",
    "#print(y_train[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(features[0][0])\n",
    "#print(features[1])\n",
    "'''\n",
    "fig, ax = plt.subplots(1, figsize=(8, 4))\n",
    "\n",
    "hog_image_rescaled = exposure.rescale_intensity(features[0][0][1], in_range=(0, 10))\n",
    "\n",
    "ax.axis('off')\n",
    "ax.imshow(hog_image_rescaled, cmap=plt.cm.gray)\n",
    "ax.set_title('Histogram of Oriented Gradients')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "blobs_log = blob_log(gray_img, max_sigma=30, num_sigma=10, threshold=.1)\n",
    "\n",
    "blobs_log[:, 2] = blobs_log[:, 2] * sqrt(2)\n",
    "\n",
    "blobs_dog = blob_dog(gray_img, max_sigma=30, threshold=.1)\n",
    "blobs_dog[:, 2] = blobs_dog[:, 2] * sqrt(2)\n",
    "\n",
    "blobs_doh = blob_doh(gray_img, max_sigma=30, threshold=.01)\n",
    "\n",
    "blobs_list = [blobs_log, blobs_dog, blobs_doh]\n",
    "colors = ['yellow', 'lime', 'red']\n",
    "titles = ['Laplacian of Gaussian', 'Difference of Gaussian',\n",
    "          'Determinant of Hessian']\n",
    "sequence = zip(blobs_list, colors, titles)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(9, 3), sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "\n",
    "for idx, (blobs, color, title) in enumerate(sequence):\n",
    "    ax[idx].set_title(title)\n",
    "    ax[idx].imshow(image, interpolation='nearest')\n",
    "    for blob in blobs:\n",
    "        y, x, r = blob\n",
    "        c = plt.Circle((x, y), r, color=color, linewidth=2, fill=False)\n",
    "        ax[idx].add_patch(c)\n",
    "    ax[idx].set_axis_off()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "fd, hog_image = hog(image, orientations=8, pixels_per_cell=(16, 16),\n",
    "                    cells_per_block=(1, 1), visualize=True, multichannel=True)\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(8, 4))\n",
    "\n",
    "hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
    "\n",
    "ax.axis('off')\n",
    "ax.imshow(hog_image_rescaled, cmap=plt.cm.gray)\n",
    "ax.set_title('Histogram of Oriented Gradients')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "print(gray_img)\n",
    "coords = corner_peaks(corner_harris(gray_img), min_distance=5)\n",
    "\n",
    "fig, (ax) = plt.subplots(1, figsize=(8, 4))\n",
    "\n",
    "ax.axis('off')\n",
    "ax.imshow(image)\n",
    "ax.plot(coords[:, 1], coords[:, 0], 'or', ms=4)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "kp = sift.detect(gray,None)\n",
    "\n",
    "siftimg=cv2.drawKeypoints(gray,kp,img)\n",
    "plt.figure()\n",
    "plt.axis('off')\n",
    "plt.imshow(siftimg)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
