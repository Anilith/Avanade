{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core import Experiment,Workspace, Run\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.train.dnn import TensorFlow\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.widgets import RunDetails\n",
    "from collections import defaultdict\n",
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from PIL import Image, ImageFilter\n",
    "import pydot\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, Activation, Flatten, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from skimage import io as io\n",
    "from skimage import exposure\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import blob_dog, blob_log, blob_doh, corner_harris, corner_subpix, corner_peaks, daisy, hog\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "import traceback\n",
    "import timeit\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.17\n",
      "Wrote the config file config.json to: C:\\Users\\olivier.claessen\\Desktop\\A.I. thesis\\aml_config\\config.json\n",
      "Workspace configuration succeeded. Skip the workspace creation steps below\n",
      "Found existing cpucluster\n",
      "Found existing gpu cluster\n"
     ]
    }
   ],
   "source": [
    "print(azureml.core.VERSION)\n",
    "\n",
    "subscription_id = os.getenv(\"SUBSCRIPTION_ID\", default=\"9bce0414-e6b9-4c79-b146-74018a4b09ac\")\n",
    "resource_group = os.getenv(\"RESOURCE_GROUP\", default=\"Thesis\")\n",
    "workspace_name = os.getenv(\"WORKSPACE_NAME\", default=\"Multi-label_classification\")\n",
    "workspace_region = os.getenv(\"WORKSPACE_REGION\", default=\"eastus2\")\n",
    "try:\n",
    "    ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\n",
    "    # write the details of the workspace to a configuration file to the notebook library\n",
    "    ws.write_config()\n",
    "    print(\"Workspace configuration succeeded. Skip the workspace creation steps below\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"Workspace not accessible. Change your parameters or create a new workspace below\")\n",
    "    \n",
    "cpu_cluster_name = \"cpucluster\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print(\"Found existing cpucluster\")\n",
    "except ComputeTargetException:\n",
    "    print(\"Creating new cpucluster\")\n",
    "    \n",
    "    # Specify the configuration for the new cluster\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_D2_V2\",\n",
    "                                                           min_nodes=0,\n",
    "                                                           max_nodes=4)\n",
    "\n",
    "    # Create the cluster with the specified name and configuration\n",
    "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "    \n",
    "    # Wait for the cluster to complete, show the output log\n",
    "    cpu_cluster.wait_for_completion(show_output=True)\n",
    "\n",
    "gpu_cluster_name = \"gpucluster\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    gpu_cluster = ComputeTarget(workspace=ws, name=gpu_cluster_name)\n",
    "    print(\"Found existing gpu cluster\")\n",
    "except ComputeTargetException:\n",
    "    print(\"Creating new gpucluster\")\n",
    "    \n",
    "    # Specify the configuration for the new cluster\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_NC6\",\n",
    "                                                           min_nodes=0,\n",
    "                                                           max_nodes=4)\n",
    "    # Create the cluster with the specified name and configuration\n",
    "    gpu_cluster = ComputeTarget.create(ws, gpu_cluster_name, compute_config)\n",
    "\n",
    "    # Wait for the cluster to complete, show the output log\n",
    "    gpu_cluster.wait_for_completion(show_output=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote the config file config.json to: C:\\Users\\olivier.claessen\\Desktop\\A.I. thesis\\aml_config\\config.json\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "# Create the workspace using the specified parameters\n",
    "ws = Workspace.create(name = workspace_name,\n",
    "                      subscription_id = subscription_id,\n",
    "                      resource_group = resource_group, \n",
    "                      location = workspace_region,\n",
    "                      create_resource_group = True,\n",
    "                      exist_ok = True)\n",
    "ws.get_details()\n",
    "\n",
    "# write the details of the workspace to a configuration file to the notebook library\n",
    "ws.write_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'multi-class_classification'\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found compute target. just use it. gpucluster\n"
     ]
    }
   ],
   "source": [
    "# choose a name for your cluster\n",
    "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"gpucluster\")\n",
    "compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n",
    "compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 4)\n",
    "\n",
    "# This example uses CPU VM. For using GPU VM, set SKU to STANDARD_NC6\n",
    "vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"STANDARD_NC6\") #\"STANDARD_D2_V2\")\n",
    "\n",
    "\n",
    "if compute_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print('found compute target. just use it. ' + compute_name)\n",
    "else:\n",
    "    print('creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size,\n",
    "                                                                min_nodes = compute_min_nodes, \n",
    "                                                                max_nodes = compute_max_nodes)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
    "    \n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "     # For a more detailed view of current AmlCompute status, use get_status()\n",
    "    print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AzureBlob multilabelclas6598396697 azureml-blobstore-cd752475-573b-4cba-aa3c-7c61a96a4f83\n"
     ]
    }
   ],
   "source": [
    "ds = ws.get_default_datastore()\n",
    "print(ds.datastore_type, ds.account_name, ds.container_name)\n",
    "#ds.upload(src_dir='./outputs', target_path='outputs', overwrite=False, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_folder = './coco-multi-label'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/annotations/instances_train2014.json\") as read_file:\n",
    "    train = json.load(read_file)\n",
    "\n",
    "with open(\"data/annotations/instances_val2014.json\") as read_file:\n",
    "    val = json.load(read_file)\n",
    "'''\n",
    "with open(\"data/annotations/instances_train2014.json\") as read_file:\n",
    "    instances = json.load(read_file)\n",
    "with open(\"data/annotations/person_keypoints_train2014.json\") as read_file:\n",
    "    keypoints = json.load(read_file)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in 2014 train: 82783\n",
      "Number of images in 2014 val: 40504\n",
      "\n",
      "Number of annotations in 2014 train: 604907\n",
      "Number of annotations in 2014 val: 291875\n",
      "\n",
      "Number of annotations/image in 2014 train: 7.307140354903785\n",
      "Number of annotations/image in 2014 val: 7.206078412008691\n",
      "\n",
      "82081\n",
      "Label density in 2014 train: 0.07307140354903784\n",
      "dict_keys(['info', 'images', 'licenses', 'annotations', 'categories'])\n",
      "\n",
      "\n",
      "1person: 0\n",
      "2bicycle: 185316\n",
      "3car: 4955\n",
      "4motorcycle: 30785\n",
      "5airplane: 6021\n",
      "6bus: 3833\n",
      "7train: 4327\n",
      "8truck: 3159\n",
      "9boat: 7050\n",
      "10traffic light: 7590\n",
      "11fire hydrant: 9159\n",
      "13stop sign: 1316\n",
      "14parking meter: 0\n",
      "15bench: 1372\n",
      "16bird: 833\n",
      "17cat: 6751\n",
      "18dog: 7290\n",
      "19horse: 3301\n",
      "20sheep: 3774\n",
      "21cow: 4666\n",
      "22elephant: 6654\n",
      "23bear: 5686\n",
      "24zebra: 3905\n",
      "25giraffe: 903\n",
      "27backpack: 3685\n",
      "28umbrella: 3596\n",
      "31handbag: 0\n",
      "32tie: 6200\n",
      "33suitcase: 7865\n",
      "34frisbee: 0\n",
      "35skis: 0\n",
      "36snowboard: 8778\n",
      "37sports ball: 4497\n",
      "38kite: 4251\n",
      "39baseball bat: 1862\n",
      "40baseball glove: 4698\n",
      "41skateboard: 1960\n",
      "42surfboard: 4392\n",
      "43tennis racket: 6560\n",
      "44bottle: 2400\n",
      "46wine glass: 2689\n",
      "47cup: 4012\n",
      "48fork: 4161\n",
      "49knife: 3411\n",
      "50spoon: 16983\n",
      "51bowl: 0\n",
      "52banana: 5618\n",
      "53apple: 14513\n",
      "54sandwich: 3918\n",
      "55orange: 5536\n",
      "56broccoli: 4287\n",
      "57carrot: 10064\n",
      "58hot dog: 6912\n",
      "59pizza: 4308\n",
      "60donut: 3089\n",
      "61cake: 4597\n",
      "62chair: 4927\n",
      "63couch: 5539\n",
      "64potted plant: 2023\n",
      "65bed: 4001\n",
      "67dining table: 4977\n",
      "70toilet: 4551\n",
      "72tv: 27147\n",
      "73laptop: 4113\n",
      "74mouse: 5918\n",
      "75remote: 2905\n",
      "76keyboard: 0\n",
      "77cell phone: 11167\n",
      "78microwave: 0\n",
      "79oven: 0\n",
      "80toaster: 2873\n",
      "81sink: 0\n",
      "82refrigerator: 4036\n",
      "84book: 3415\n",
      "85clock: 1517\n",
      "86vase: 4122\n",
      "87scissors: 1980\n",
      "88teddy bear: 4460\n",
      "89hair drier: 1189\n",
      "90toothbrush: 2302\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-9592a26f7f1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;31m#print(categories)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_categories\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcategories\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"name\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\": \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_categories\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     \u001b[0mtrain_categories\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"name\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_categories\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;31m#for i in range(0, len(val_categories)):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "categories = train[\"categories\"]\n",
    "#print(categories)\n",
    "train_images = train[\"images\"]\n",
    "val_images = val[\"images\"]\n",
    "print(\"Number of images in 2014 train: \"+str(len(train_images)))\n",
    "print(\"Number of images in 2014 val: \"+str(len(val_images)) +\"\\n\")\n",
    "train_annotations = train[\"annotations\"]\n",
    "val_annotations = val[\"annotations\"]\n",
    "#print(train_annotations[1:20])\n",
    "val_annotations = val[\"annotations\"]\n",
    "print(\"Number of annotations in 2014 train: \"+str(len(train_annotations)))\n",
    "print(\"Number of annotations in 2014 val: \"+str(len(val_annotations)) + \"\\n\")\n",
    "print(\"Number of annotations/image in 2014 train: \"+str(len(train_annotations)/len(train_images)))\n",
    "print(\"Number of annotations/image in 2014 val: \" + str(len(val_annotations)/len(val_images)) + \"\\n\")\n",
    "train_categories = np.zeros(100, dtype=object)\n",
    "#val_categories = np.zeros(100, dtype=object)\n",
    "#itemsets = [[] for i in range(581922)]\n",
    "itemsets = defaultdict(list)\n",
    "for annotation in train_annotations:\n",
    "    train_categories[annotation['category_id']] += 1\n",
    "    itemsets[annotation['image_id']].append(annotation['category_id'])\n",
    "unique_itemsets = []\n",
    "for entry in itemsets:\n",
    "    if(entry not in unique_itemsets):\n",
    "        unique_itemsets.append(entry)\n",
    "print(len(unique_itemsets))\n",
    "'''\n",
    "for annotation in val_annotations:\n",
    "    val_categories[annotation['category_id']] += 1\n",
    "train_categories = train_categories[train_categories != 0]\n",
    "val_categories = val_categories[val_categories != 0]\n",
    "'''\n",
    "print(\"Label density in 2014 train: \"+str(len(train_annotations)/len(train_categories)/len(train_images)))\n",
    "#print(\"Label density in 2014 val: \"+str(len(val_annotations)/len(val_categories)/len(val_images)))\n",
    "print(train.keys())\n",
    "print(\"\\n\")\n",
    "#print(images[1:10])\n",
    "#print(\"\\n\")\n",
    "#print(annotations[1:10])\n",
    "#print(\"\\n\")\n",
    "#print(categories)\n",
    "#for i in range(0, len(train_categories)):\n",
    "#    print(str(categories[i][\"id\"]) + categories[i][\"name\"] + \": \" + str(train_categories[i]))\n",
    "#    train_categories[i] = (categories[i][\"name\"], train_categories[i])\n",
    "#for i in range(0, len(val_categories)):\n",
    "    #print(categories[i][\"name\"] + \": \" + str(train_categories[i]))\n",
    "#    val_categories[i] = (categories[i][\"name\"], val_categories[i])\n",
    "plt.figure(1)\n",
    "plt.subplot(211)\n",
    "plt.plot([i[1] for i in train_categories])\n",
    "#plt.subplot(212)\n",
    "#plt.plot([i[1] for i in val_categories])\n",
    "#plt.show()\n",
    "train_categories = sorted(train_categories, key=lambda tup: tup[1], reverse=False)\n",
    "#val_categories = sorted(val_categories, key=lambda tup: tup[1], reverse=False)\n",
    "print(\"\\n10 least used features \\n\")\n",
    "print(train_categories[0:9])\n",
    "print(\"\\n\")\n",
    "#print(val_categories[0:9])\n",
    "print(\"\\n10 most used features \\n\")\n",
    "print(train_categories[-10:])\n",
    "print(\"\\n\")\n",
    "#print(val_categories[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "# Get a sorted list of the objects and their sizes\n",
    "sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = 49 #9,25,30,34,36,49\n",
    "def findAnnotations(id, property):\n",
    "    items = []\n",
    "    for annotation in train_annotations: \n",
    "        if annotation[property] == id:\n",
    "            items.append(annotation)\n",
    "    return items\n",
    "items = findAnnotations(image_id, 'image_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findValueDictionary(dict,key,value, returnkey):\n",
    "    for entry in dict:\n",
    "        if entry[key] == value:\n",
    "            return entry[returnkey]\n",
    "\n",
    "image_id_string = str(image_id).zfill(12)\n",
    "image = np.array(Image.open('data/train2014/COCO_train2014_'+ image_id_string +'.jpg'), dtype=np.uint8)\n",
    "fig,ax = plt.subplots(1)\n",
    "ax.imshow(image)\n",
    "colors = np.random.random((len(categories)+10, 3))\n",
    "i=0\n",
    "bbox_list = []\n",
    "item_list = []\n",
    "for item in items:\n",
    "    label = findValueDictionary(categories, 'id', item['category_id'], 'name')\n",
    "    rect = patches.Rectangle((item['bbox'][0], (item['bbox'][1])), item['bbox'][2], item['bbox'][3],linewidth=1,edgecolor=colors[item['category_id']-1],facecolor='none', label= label)\n",
    "    ax.add_patch(rect)\n",
    "    bbox_list.append(rect)\n",
    "    item_list.append(item['category_id'])\n",
    "#print(items)\n",
    "plt.figure(figsize=(3,4))\n",
    "plt.legend(handles=bbox_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core import Run\n",
    "import cv2\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import os\n",
    "from PIL import Image, ImageFilter\n",
    "from skimage import io as io\n",
    "from skimage import exposure\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import blob_dog, blob_log, blob_doh, corner_harris, corner_subpix, corner_peaks, daisy, hog\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from time import time\n",
    "\n",
    "def loadAnnotations(fileLocation):\n",
    "    with open(fileLocation) as read_file:\n",
    "        annotations = json.load(read_file)\n",
    "    return annotations\n",
    "    \n",
    "def getBoundingBox(x,y,w,h,img):\n",
    "    return img[y:y+h,x:x+w]\n",
    "\n",
    "def findAnnotations(id, property, annotations):\n",
    "    items = []\n",
    "    for annotation in annotations: \n",
    "        if annotation[property] == id:\n",
    "            items.append(annotation)\n",
    "    return items\n",
    "\n",
    "def zca_whitening_matrix(X):\n",
    "    # Covariance matrix [column-wise variables]: Sigma = (X-mu)' * (X-mu) / N\n",
    "    sigma = np.cov(X, rowvar=True) # [M x M]\n",
    "    # Singular Value Decomposition. X = U * np.diag(S) * V\n",
    "    U,S,V = np.linalg.svd(sigma)\n",
    "        # U: [M x M] eigenvectors of sigma.\n",
    "        # S: [M x 1] eigenvalues of sigma.\n",
    "        # V: [M x M] transpose of U\n",
    "    # Whitening constant: prevents division by zero\n",
    "    epsilon = 1e-5\n",
    "    # ZCA Whitening matrix: U * Lambda * U'\n",
    "    ZCAMatrix = np.dot(U, np.dot(np.diag(1.0/np.sqrt(S + epsilon)), U.T)) # [M x M]\n",
    "    return ZCAMatrix\n",
    "\n",
    "def preProcessImage(img):\n",
    "    img = np.asarray(img)\n",
    "    #img = rgb2gray(img)\n",
    "    #img = cv2.GaussianBlur(img,(5,5),0)\n",
    "    #img = cv2.medianBlur(img,5)\n",
    "    #img = cv2.bilateralFilter(img,9,75,75)\n",
    "    #img = cv2.blur(img,(5,5))\n",
    "    #kernel = np.ones((5,5),np.float32)/25\n",
    "    #img = cv2.filter2D(img,-1,kernel)\n",
    "    return img\n",
    "\n",
    "def noisy(image):\n",
    "    row,col,ch = image.shape\n",
    "    s_vs_p = 0.5\n",
    "    amount = 0.004\n",
    "    out = np.copy(image)\n",
    "    # Salt mode\n",
    "    num_salt = np.ceil(amount * image.size * s_vs_p)\n",
    "    coords = [np.random.randint(0, i - 1, int(num_salt))\n",
    "          for i in image.shape]\n",
    "    out[coords] = 1\n",
    "\n",
    "    # Pepper mode\n",
    "    num_pepper = np.ceil(amount* image.size * (1. - s_vs_p))\n",
    "    coords = [np.random.randint(0, i - 1, int(num_pepper))\n",
    "          for i in image.shape]\n",
    "    out[coords] = 0\n",
    "    return out\n",
    "\n",
    "def getBoundingBoxesPictures(annotations, path):\n",
    "    bounded_images = []\n",
    "    bounded_annotations = []\n",
    "    try:\n",
    "        for annotation in annotations:\n",
    "            image_id = annotation['image_id']\n",
    "            image_id_string = str(image_id).zfill(12)\n",
    "            image = Image.open(path + image_id_string +'.jpg').convert('RGB')\n",
    "            image = preProcessImage(image) \n",
    "            image_resized = resize(getBoundingBox(int(annotation['bbox'][0]),int(annotation['bbox'][1]),int(annotation['bbox'][2]),int(annotation['bbox'][3]),image)\n",
    "                                   , (48, 48),\n",
    "                           anti_aliasing=True)\n",
    "            bounded_images.append(image_resized)\n",
    "            bounded_annotations.append(annotation['category_id'])     \n",
    "    except Exception as ex:\n",
    "            print(ex)   \n",
    "    bounded_images = np.asarray(bounded_images)\n",
    "    bounded_annotations = np.asarray(bounded_annotations)\n",
    "    return bounded_images,bounded_annotations\n",
    "\n",
    "def calculateHogFeatures(gray_image, o, pixels, cells):\n",
    "    features = hog(gray_image, orientations=o, \n",
    "                              pixels_per_cell=(pixels, pixels),\n",
    "                              cells_per_block=(cells, cells), \n",
    "                              transform_sqrt=True, \n",
    "                              visualize=False, block_norm = \"L2-Hys\")\n",
    "    return features\n",
    "def calculateDaisyFeatures(gray_image):\n",
    "    descs = daisy(gray_image, step=180, radius=15, rings=3, histograms=6,\n",
    "                         orientations=8, visualize=False)\n",
    "    descs_num = descs.shape[0] * descs.shape[1]\n",
    "    return descs.reshape(descs.size).tolist()\n",
    "\n",
    "def calculateDoG(gray_image):\n",
    "    blobs_dog = blob_dog(gray_img, max_sigma=30, threshold=.1)\n",
    "    blobs_dog[:, 2] = blobs_dog[:, 2] * sqrt(2)\n",
    "    return blobs_dog\n",
    "\n",
    "def calculateSIFT(sift, gray_image):\n",
    "    kp = sift.detect(gray_image,None)\n",
    "    return kp\n",
    "\n",
    "def calculateFeatures(imgs):\n",
    "    #sift = cv2.xfeatures2d.SIFT_create()\n",
    "    hog_features = []\n",
    "    dog_features = []\n",
    "    daisy_features = []\n",
    "    sift_features = []\n",
    "    i = 0;\n",
    "    for img in imgs:\n",
    "        hog_features.append(calculateHogFeatures(img,8,16,1))\n",
    "        #dog_features.append(calculateDoG(img))\n",
    "        #sift_features.append(calculateSIFT(sift, img))\n",
    "        daisy_features.append(calculateDaisyFeatures(img))\n",
    "    return hog_features, daisy_features\n",
    "\n",
    "def svmFit(x_train, y_train):\n",
    "    print(\"Fitting the classifier to train\")\n",
    "    t0 = time()\n",
    "    param_grid = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "                  'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], }\n",
    "    clf = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'),\n",
    "                       param_grid, cv=5)\n",
    "    clf = clf.fit(x_train, y_train)\n",
    "    print(\"Completed in %0.3fs\" % (time() - t0))\n",
    "    print(\"Best estimator found by grid search:\")\n",
    "    print(clf.best_estimator_)\n",
    "    return clf\n",
    "\n",
    "def saveModel(model, filename):\n",
    "    print(\"Saving file...\")\n",
    "    joblib.dump(model, open(filename, 'wb'))\n",
    "    print(\"File saved\")\n",
    "    \n",
    "def loadModel(filename):\n",
    "    print(\"loading file...\")\n",
    "    joblib.load(filename)\n",
    "    print(\"Model loaded\")\n",
    "    \n",
    "def svmPredict(x_test, y_test, model):\n",
    "    print(\"Predicting the test set\")\n",
    "    t0 = time()\n",
    "    y_pred = model.predict(x_test)\n",
    "    print(\"Completed in %0.3fs\" % (time() - t0))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "def randomForestFit(x_train, y_train, estimators):\n",
    "    print(\"Fitting the classifier to train\")\n",
    "    t0 = time()\n",
    "    rf = RandomForestClassifier(n_estimators=estimators)\n",
    "    rf.fit(x_train, y_train);\n",
    "    print(\"Completed in %0.3fs\" % (time() - t0))\n",
    "    return rf\n",
    "\n",
    "def rfPredict(x_test, y_test, model):\n",
    "    print(\"Predicting the test set\")\n",
    "    t0 = time()\n",
    "    y_pred = model.predict(x_test)\n",
    "    print(\"Completed in %0.3fs\" % (time() - t0))\n",
    "    errors = abs(y_pred - y_test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "  \n",
    "def constructCNN(conv_layer, layer_size, kernel_size, dense_size, dense_layer, dropout, num_classes, x_train):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(layer_size, (kernel_size, kernel_size), input_shape=x_train.shape[1:]))\n",
    "\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    for l in range(conv_layer-1):\n",
    "        model.add(Conv2D(layer_size, (kernel_size, kernel_size)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    if(dropout):\n",
    "        model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    for j in range(dense_layer):\n",
    "        model.add(Dense(dense_size))\n",
    "        model.add(Activation('relu'))\n",
    "    if(dropout):\n",
    "        model.add(Dropout(0.25))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "    \n",
    "# Create a function called \"chunks\" with two arguments, l and n:\n",
    "def chunks(l, n):\n",
    "    # For item i in a range that is a length of l,\n",
    "    for i in range(0, len(l), n):\n",
    "        # Create an index range for l of n items:\n",
    "        yield l[i:i+n]\n",
    "\n",
    "def splitPreprocessing(splits, data_folder, path):\n",
    "    labels = []\n",
    "    features = np.asarray([[],[]])\n",
    "    for split in splits:\n",
    "        bboxes = getBoundingBoxesPictures(split, os.path.join(data_folder, path))\n",
    "        splitfeatures = calculateFeatures(bboxes[0])\n",
    "        features = np.append(features, splitfeatures,1)\n",
    "        labels.extend(bboxes[1])\n",
    "    return labels, features.tolist()\n",
    "\n",
    "data_folder = 'data'\n",
    "\n",
    "path = \"train2014/COCO_train2014_\"\n",
    "valpath = \"val2014/val2014/COCO_val2014_\"\n",
    "category = \"category_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17457, 48, 48, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72,)\n",
      "(152,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (72,) (152,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-ea530c1d82ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbbox\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculateFeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m x_trainfeat, x_testfeat, y_trainfeat, y_testfeat = train_test_split(\n\u001b[0;32m     26\u001b[0m     features, y_train, stratify=y_train,  test_size=0.25, random_state=42)\n",
      "\u001b[1;32m<ipython-input-22-12b2be83ebdb>\u001b[0m in \u001b[0;36mcalculateFeatures\u001b[1;34m(imgs)\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcalculateHogFeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcalculateDaisyFeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcalculateHogFeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcalculateDaisyFeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m         \u001b[1;31m#hog_features.append(calculateHogFeatures(img,8,16,1))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;31m#dog_features.append(calculateDoG(img))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (72,) (152,) "
     ]
    }
   ],
   "source": [
    "'''\n",
    "train_annotations = loadAnnotations(os.path.join(data_folder, 'annotations/instances_train2014.json'))\n",
    "train_annotations = train_annotations[\"annotations\"]\n",
    "\n",
    "val_annotations = loadAnnotations(os.path.join(data_folder, 'annotations/instances_val2014.json'))\n",
    "val_annotations = val_annotations[\"annotations\"]\n",
    "'''\n",
    "'''\n",
    "#testsplits = list(chunks(dummy_annotations, 50))\n",
    "#labels, features = splitPreprocessing(testsplits, data_folder, path)\n",
    "\n",
    "'''\n",
    "\n",
    "categories_subset = [2,4]\n",
    "bbox = getBoundingBoxesPictures(findAnnotations(categories_subset[0], category, train_annotations),  os.path.join(data_folder, path))\n",
    "imgs = bbox[0]\n",
    "categories_subset.pop(0)\n",
    "labels = bbox[1]\n",
    "for category_id in categories_subset:\n",
    "    bbox = getBoundingBoxesPictures(findAnnotations(category_id, category, train_annotations),  os.path.join(data_folder, path))\n",
    "    imgs = np.concatenate((imgs,bbox[0]))\n",
    "    labels = np.concatenate((labels,bbox[1]))\n",
    "\n",
    "features = calculateFeatures(imgs)\n",
    "x_trainfeat, x_testfeat, y_trainfeat, y_testfeat = train_test_split(\n",
    "    features, y_train, stratify=y_train,  test_size=0.25, random_state=42)\n",
    "svm = svmFit(x_trainfeat, y_trainfeat)\n",
    "\n",
    "svmResults = svmPredict(x_testfeat, y_testfeat, svm)\n",
    "\n",
    "'''\n",
    "x_trainfeat, x_testfeat, y_trainfeat, y_testfeat = train_test_split(\n",
    "    features[1], y_train, stratify=y_train, test_size=0.25, random_state=42)\n",
    "svmDaisy = svmFit(x_trainfeat, y_trainfeat)\n",
    "svmDaisyResults = svmPredict(x_testfeat, y_testfeat, svmDaisy)\n",
    "#saveModel(svm, 'SVM_DAISY.sav')\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the classifier to train\n",
      "Completed in 289.998s\n",
      "Predicting the test set\n",
      "Completed in 4.329s\n",
      "Accuracy: 0.5256624963057827\n",
      "Fitting the classifier to train\n",
      "Completed in 451.803s\n",
      "Predicting the test set\n",
      "Completed in 4.565s\n",
      "Accuracy: 0.5697960792040193\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "categories_subset = [2,4]#[2,4,5,6,7]\n",
    "bbox = getBoundingBoxesPictures(findAnnotations(categories_subset[0], category, train_annotations),  os.path.join(data_folder, path))\n",
    "imgs = bbox[0]\n",
    "categories_subset.pop(0)\n",
    "labels = bbox[1]\n",
    "for category_id in categories_subset:\n",
    "    bbox = getBoundingBoxesPictures(findAnnotations(category_id, category, train_annotations),  os.path.join(data_folder, path))\n",
    "    imgs = np.concatenate((imgs,bbox[0]))\n",
    "    labels = np.concatenate((labels,bbox[1]))\n",
    "'''\n",
    "features = calculateFeatures(imgs)\n",
    "\n",
    "x_trainfeat, x_testfeat, y_trainfeat, y_testfeat = train_test_split(\n",
    "    features[0], y_train, test_size=0.25, random_state=42)\n",
    "rfHOG = randomForestFit(x_trainfeat, y_trainfeat, 1000)\n",
    "rfHOG_results = rfPredict(x_testfeat, y_testfeat, rfHOG)\n",
    "x_trainfeat, x_testfeat, y_trainfeat, y_testfeat = train_test_split(\n",
    "    features[1], y_train, test_size=0.25, random_state=42)\n",
    "rfDaisy = randomForestFit(x_trainfeat, y_trainfeat, 1000)\n",
    "rfDaisy_results = rfPredict(x_testfeat, y_testfeat, rfDaisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'itemsets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-fb55d081417b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mimage_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage_tags\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mpictureData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetPictures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitemsets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m18\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;31m#print(pictureData)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'itemsets' is not defined"
     ]
    }
   ],
   "source": [
    "# width 578.2023976316078\n",
    "# heigth 483.5494085111049\n",
    "\n",
    "path = \"data/train2014/COCO_train2014_\"\n",
    "def getPictures(itemsets, path, instance):\n",
    "    images = []\n",
    "    image_ids = []\n",
    "    image_tags = []\n",
    "    avg_width, avg_height = (0,0)\n",
    "    try:\n",
    "        for itemset in itemsets:\n",
    "            print(itemset)\n",
    "            print(itemsets[itemset])\n",
    "            if(instance in itemsets[itemset]):\n",
    "                image_id_string = str(itemset).zfill(12)\n",
    "                image_ids.append(str(itemset))\n",
    "                image = Image.open(path + image_id_string +'.jpg')\n",
    "                processed_img = preProcessImage(image)\n",
    "                image.close()\n",
    "                resized_image = resize(processed_img, (350, 292),anti_aliasing=True)\n",
    "                images.append(resized_image)\n",
    "                image_tags.append(itemsets[itemset])\n",
    "    except Exception as ex:\n",
    "            print(ex)   \n",
    "    return image_ids,images,image_tags\n",
    "\n",
    "pictureData = getPictures(itemsets, path, 18)\n",
    "#print(pictureData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\olivier.claessen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\skimage\\transform\\_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "c:\\users\\olivier.claessen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:334: UserWarning: This ImageDataGenerator specifies `zca_whitening`, which overrides setting of `featurewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    }
   ],
   "source": [
    "def example_errors():\n",
    "    generator_test.reset()\n",
    "    \n",
    "    # Predict the classes for all images in the test-set.\n",
    "    y_pred = new_model.predict_generator(generator_test,\n",
    "                                         steps=steps_test)\n",
    "\n",
    "    # Convert the predicted classes from arrays to integers.\n",
    "    cls_pred = np.argmax(y_pred,axis=1)\n",
    "\n",
    "    # Plot examples of mis-classified images.\n",
    "    plot_example_errors(cls_pred)\n",
    "    \n",
    "    # Print the confusion matrix.\n",
    "    print_confusion_matrix(cls_pred)\n",
    "categories_subset = [2,6,19]\n",
    "bbox = getBoundingBoxesPictures(findAnnotations(categories_subset[0], category, train_annotations),  os.path.join(data_folder, path))\n",
    "bbox_val = getBoundingBoxesPictures(findAnnotations(categories_subset[0], category, val_annotations),  os.path.join(data_folder, valpath))\n",
    "imgs = bbox[0]\n",
    "imgs_val = bbox_val[0]\n",
    "y_train = bbox[1]\n",
    "y_test = bbox_val[1]\n",
    "categories_subset.pop(0)\n",
    "for category_id in categories_subset:\n",
    "    bbox = getBoundingBoxesPictures(findAnnotations(category_id, category, train_annotations),  os.path.join(data_folder, path))\n",
    "    imgs = np.concatenate((imgs,bbox[0]))\n",
    "    y_train = np.concatenate((y_train,bbox[1]))\n",
    "    bbox_val = getBoundingBoxesPictures(findAnnotations(category_id, category, val_annotations),  os.path.join(data_folder, valpath))\n",
    "    imgs_val = np.concatenate((imgs_val,bbox_val[0]))\n",
    "    y_test = np.concatenate((y_test,bbox_val[1]))\n",
    "\n",
    "#images = np.asarray(pictureData[1])\n",
    "\n",
    "'''\n",
    "#x_train, x_test, y_train, y_test = train_test_split(\n",
    "#    imgs, y_train, test_size=0.25, random_state=42)\n",
    "'''\n",
    "x_train = imgs/255\n",
    "x_test = imgs_val/255\n",
    "\n",
    "for (i,value) in enumerate(y_train):\n",
    "    if value == 2:\n",
    "        y_train[i] = 0\n",
    "        continue\n",
    "    if value == 6:\n",
    "        y_train[i] = 1\n",
    "        continue\n",
    "    if value == 19:\n",
    "        y_train[i] = 2\n",
    "        continue\n",
    "    if value == 20:\n",
    "        y_train[i] = 3\n",
    "        continue\n",
    "    if value == 33:\n",
    "        y_train[i] = 4\n",
    "        continue\n",
    "    if value == 46:\n",
    "        y_train[i] = 5\n",
    "        continue\n",
    "    if value == 49:\n",
    "        y_train[i] = 6\n",
    "        continue\n",
    "    if value == 55:\n",
    "        y_train[i] = 7\n",
    "        continue\n",
    "for (i,value) in enumerate(y_test):\n",
    "    if value == 2:\n",
    "        y_test[i] = 0\n",
    "        continue\n",
    "    if value == 6:\n",
    "        y_test[i] = 1\n",
    "        continue\n",
    "    if value == 19:\n",
    "        y_test[i] = 2\n",
    "        continue\n",
    "    if value == 20:\n",
    "        y_test[i] = 3\n",
    "        continue\n",
    "    if value == 33:\n",
    "        y_test[i] = 4\n",
    "        continue\n",
    "    if value == 46:\n",
    "        y_test[i] = 5\n",
    "        continue\n",
    "    if value == 49:\n",
    "        y_test[i] = 6\n",
    "        continue\n",
    "    if value == 55:\n",
    "        y_test[i] = 7\n",
    "        continue\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    zca_whitening=True, \n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "datagen.fit(x_train)\n",
    "datagen_test = ImageDataGenerator(zca_whitening=True)\n",
    "datagen_test.fit(x_test)         \n",
    "\n",
    "ylabels_test = to_categorical(y_test)\n",
    "ylabels_train = to_categorical(y_train)\n",
    "#joblib.dump(value=ylabels_train, filename='outputs/ylabels_train2,6,19,20,33,46,49,55c.npy')\n",
    "#joblib.dump(value=ylabels_test, filename='outputs/ylabels_test2,6,19,20,33,46,49,55c.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = joblib.load('outputs/x_train2,6,19,20,33,46c.npy')\n",
    "x_test = joblib.load('outputs/x_test2,6,19,20,33,46c.npy')\n",
    "ylabels_train = joblib.load('outputs/y_testlabels2,6,19,20,33,46.npy')\n",
    "ylabels_test = joblib.load('outputs/y_trainlabels2,6,19,20,33,46.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\olivier.claessen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:339: UserWarning: This ImageDataGenerator specifies `zca_whitening` which overrides setting of`featurewise_std_normalization`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True, \n",
    "    zca_whitening=True,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "datagen.fit(x_train)\n",
    "datagen_test = ImageDataGenerator(featurewise_center=True, \n",
    "    zca_whitening=True,)\n",
    "datagen_test.fit(x_test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-conv-64-nodes-1-dense-64-dense_size-3-kernel-1554217025\n",
      "Epoch 1/15\n",
      "6695/6695 [==============================] - 15s 2ms/sample - loss: 1.1521 - acc: 0.3695\n",
      "436/436 [==============================] - 308s 707ms/step - loss: 0.8386 - acc: 0.6225 - val_loss: 1.1511 - val_acc: 0.3695\n",
      "Epoch 2/15\n",
      "159/436 [=========>....................] - ETA: 2:56 - loss: 0.6977 - acc: 0.6994"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-d53734a7338d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m                     \u001b[1;31m#model.fit(x_train, ylabels_train.astype(np.float32), batch_size=70, epochs=100, validation_data = (x_test, ylabels_test), callbacks = [tensorboard],shuffle=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                     model.fit_generator(datagen.flow(x_train, ylabels_train, batch_size=32,shuffle=True), \n\u001b[1;32m---> 22\u001b[1;33m                                         epochs=15, callbacks = [early_stopping_monitor], validation_data = (x_test, ylabels_test))\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m '''\n",
      "\u001b[1;32mc:\\users\\olivier.claessen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1424\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1425\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1426\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1428\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32mc:\\users\\olivier.claessen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m       \u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m       \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\olivier.claessen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1189\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_fit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\olivier.claessen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3076\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[1;32mc:\\users\\olivier.claessen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "early_stopping_monitor = EarlyStopping(patience = 3)\n",
    "\n",
    "\n",
    "\n",
    "dense_layers = [1]\n",
    "layer_sizes = [64]\n",
    "dense_sizes = [64]\n",
    "conv_layers = [1]\n",
    "kernel_sizes = [3]\n",
    "for dense_layer in dense_layers:\n",
    "    for dense_size in dense_sizes:\n",
    "        for kernel_size in kernel_sizes:\n",
    "            for layer_size in layer_sizes:\n",
    "                for conv_layer in conv_layers:\n",
    "                    model = constructCNN(conv_layer, layer_size, kernel_size, dense_size, dense_layer, True, 3, x_train)\n",
    "                    NAME = \"{}-conv-{}-nodes-{}-dense-{}-dense_size-{}-kernel-{}\".format(conv_layer, layer_size, dense_layer, dense_size, kernel_size, int(time()))\n",
    "                    print(NAME)\n",
    "                    tensorboard = TensorBoard(log_dir=\"logs2,6,19,20,33,46,49,55c/{}\".format(NAME))\n",
    "                    #model.fit(x_train, ylabels_train.astype(np.float32), batch_size=70, epochs=100, validation_data = (x_test, ylabels_test), callbacks = [tensorboard],shuffle=True)\n",
    "                    model.fit_generator(datagen.flow(x_train, ylabels_train, batch_size=32,shuffle=True), \n",
    "                                        epochs=15, callbacks = [early_stopping_monitor], validation_data = (x_test, ylabels_test))\n",
    "\n",
    "'''\n",
    "y_pred = model.predict_classes(x_test)\n",
    "true_preds = [(x,y) for (x,y,p) in zip(X_test, y_test, y_pred) if y == p]\n",
    "false_preds = [(x,y,p) for (x,y,p) in zip(X_test, y_test, y_pred) if y != p]\n",
    "print(\"Number of true predictions: \", len(true_preds))\n",
    "print(\"Number of false predictions:\", len(false_preds))\n",
    "'''\n",
    "'''\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), input_shape=x_train.shape[1:], activation = 'relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(8))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "optimizer='adam',\n",
    "metrics=['accuracy'])\n",
    "        \n",
    "print(\"2x3x3x128,2x3x3x64,0.25,D64,0.25 model.fit\")\n",
    "model.fit(x_train, ylabels_train.astype(np.float32), batch_size=70, epochs=100, validation_data = (x_test, ylabels_test), callbacks = [])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $script_folder/train.py\n",
    "\n",
    "import argparse\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core import Run\n",
    "\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import os\n",
    "from PIL import Image, ImageFilter\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import blob_dog, blob_log, blob_doh, corner_harris, corner_subpix, corner_peaks, daisy, hog\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "import time\n",
    "\n",
    "def loadAnnotations(fileLocation):\n",
    "    with open(fileLocation) as read_file:\n",
    "        annotations = json.load(read_file)\n",
    "    return annotations\n",
    "    \n",
    "def getBoundingBox(x,y,w,h,img):\n",
    "    return img[y:y+h,x:x+w]\n",
    "\n",
    "def findAnnotations(id, property, annotations):\n",
    "    items = []\n",
    "    for annotation in annotations: \n",
    "        if annotation[property] == id:\n",
    "            items.append(annotation)\n",
    "    return items\n",
    "\n",
    "def preProcessImage(img):\n",
    "    img = np.asarray(img)\n",
    "    img = rgb2gray(img)\n",
    "    #img = cv2.GaussianBlur(img,(5,5),0)\n",
    "    #img = cv2.medianBlur(img,5)\n",
    "    #img = cv2.bilateralFilter(img,9,75,75)\n",
    "    #img = cv2.blur(img,(5,5))\n",
    "    #kernel = np.ones((5,5),np.float32)/25\n",
    "    #img = cv2.filter2D(img,-1,kernel)\n",
    "    return img\n",
    "\n",
    "def getBoundingBoxesPictures(annotations, path):\n",
    "    bounded_images = []\n",
    "    bounded_annotations = []\n",
    "    try:\n",
    "        for annotation in annotations:\n",
    "            image_id = annotation['image_id']\n",
    "            image_id_string = str(image_id).zfill(12)\n",
    "            image = Image.open(path + image_id_string +'.jpg')\n",
    "            image = preProcessImage(image) \n",
    "            image_resized = resize(getBoundingBox(int(annotation['bbox'][0]),int(annotation['bbox'][1]),int(annotation['bbox'][2]),int(annotation['bbox'][3]),image)\n",
    "                                   , (64, 64),\n",
    "                           anti_aliasing=True)\n",
    "            bounded_images.append(image_resized)\n",
    "            bounded_annotations.append(annotation['category_id'])     \n",
    "    except Exception as ex:\n",
    "            print(ex)   \n",
    "    bounded_images = np.asarray(bounded_images)\n",
    "    bounded_annotations = np.asarray(bounded_annotations)\n",
    "    return bounded_images,bounded_annotations\n",
    "\n",
    "def calculateHogFeatures(gray_image, o, pixels, cells):\n",
    "    features = hog(gray_image, orientations=o, \n",
    "                              pixels_per_cell=(pixels, pixels),\n",
    "                              cells_per_block=(cells, cells), \n",
    "                              transform_sqrt=True, \n",
    "                              visualize=False, block_norm = \"L2-Hys\")\n",
    "    return features\n",
    "def calculateDaisyFeatures(gray_image):\n",
    "    descs = daisy(gray_image, step=180, radius=15, rings=3, histograms=6,\n",
    "                         orientations=8, visualize=False)\n",
    "    descs_num = descs.shape[0] * descs.shape[1]\n",
    "    return descs.reshape(descs.size).tolist()\n",
    "\n",
    "def calculateDoG(gray_image):\n",
    "    blobs_dog = blob_dog(gray_img, max_sigma=30, threshold=.1)\n",
    "    blobs_dog[:, 2] = blobs_dog[:, 2] * sqrt(2)\n",
    "    return blobs_dog\n",
    "\n",
    "def calculateSIFT(sift, gray_image):\n",
    "    kp = sift.detect(gray_image,None)\n",
    "    return kp\n",
    "\n",
    "def calculateFeatures(imgs):\n",
    "    #sift = cv2.xfeatures2d.SIFT_create()\n",
    "    hog_features = []\n",
    "    dog_features = []\n",
    "    daisy_features = []\n",
    "    sift_features = []\n",
    "    i = 0;\n",
    "    for img in imgs:\n",
    "        hog_features.append(calculateHogFeatures(img,8,16,1))\n",
    "        #dog_features.append(calculateDoG(img))\n",
    "        #sift_features.append(calculateSIFT(sift, img))\n",
    "        daisy_features.append(calculateDaisyFeatures(img))\n",
    "    return hog_features, daisy_features\n",
    "\n",
    "def svmFit(x_train, y_train):\n",
    "    print(\"Fitting the classifier to train\")\n",
    "    t0 = time.time()\n",
    "    param_grid = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "                  'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], }\n",
    "    clf = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'),\n",
    "                       param_grid, cv=5)\n",
    "    clf = clf.fit(x_train, y_train)\n",
    "    print(\"Completed in %0.3fs\" % (time.time() - t0))\n",
    "    print(\"Best estimator found by grid search:\")\n",
    "    print(clf.best_estimator_)\n",
    "    return clf\n",
    "\n",
    "def saveModel(model, filename):\n",
    "    print(\"Saving file...\")\n",
    "    joblib.dump(model, open(filename, 'wb'))\n",
    "    print(\"File saved\")\n",
    "    \n",
    "def loadModel(filename):\n",
    "    print(\"loading file...\")\n",
    "    model = joblib.load(filename)\n",
    "    print(\"Model loaded\")\n",
    "    return model\n",
    "    \n",
    "def svmPredict(x_test, y_test, model):\n",
    "    print(\"Predicting the test set\")\n",
    "    t0 = time.time()\n",
    "    y_pred = model.predict(x_test)\n",
    "    print(\"Completed in %0.3fs\" % (time.time() - t0))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "def randomForestFit(x_train, y_train, estimators, random_state):\n",
    "    print(\"Fitting the classifier to train\")\n",
    "    t0 = time.time()\n",
    "    rf = RandomForestRegressor(n_estimators = estimators, random_state = random_state)\n",
    "    rf.fit(x_train, y_train);\n",
    "    print(\"Completed in %0.3fs\" % (time.time() - t0))\n",
    "    return rf\n",
    "\n",
    "def rfPredict(x_test, y_test, model):\n",
    "    print(\"Predicting the test set\")\n",
    "    t0 = time.time()\n",
    "    y_pred = model.predict(x_test)\n",
    "    print(\"Completed in %0.3fs\" % (time.time() - t0))\n",
    "    errors = abs(y_pred - y_test)\n",
    "    print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "    # Calculate mean absolute percentage error (MAPE)\n",
    "    mape = 100 * (errors / y_test)\n",
    "    # Calculate and display accuracy\n",
    "    accuracy = 100 - np.mean(mape)\n",
    "    print('Accuracy:', round(accuracy, 2), '%.')\n",
    "    \n",
    "    \n",
    "# Create a function called \"chunks\" with two arguments, l and n:\n",
    "def chunks(l, n):\n",
    "    # For item i in a range that is a length of l,\n",
    "    for i in range(0, len(l), n):\n",
    "        # Create an index range for l of n items:\n",
    "        yield l[i:i+n]\n",
    "\n",
    "def splitPreprocessing(splits, data_folder, path):\n",
    "    labels = []\n",
    "    features = np.asarray([[],[]])\n",
    "    for split in splits:\n",
    "        bboxes = getBoundingBoxesPictures(split, os.path.join(data_folder, path))\n",
    "        splitfeatures = calculateFeatures(bboxes[0])\n",
    "        features = np.append(features, splitfeatures,1)\n",
    "        labels.extend(bboxes[1])\n",
    "    return labels, features.tolist()\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data-folder', type=str, dest='data_folder', help='data folder mounting point')\n",
    "args = parser.parse_args()\n",
    "data_folder = os.path.join(args.data_folder, 'data')\n",
    "print('Data folder:', data_folder)\n",
    "run = Run.get_context()\n",
    "\n",
    "path = \"train2014/COCO_train2014_\"\n",
    "category = \"category_id\"\n",
    "train_annotations = loadAnnotations(os.path.join(data_folder, 'annotations/instances_train2014.json'))\n",
    "train_annotations = train_annotations[\"annotations\"]\n",
    "'''\n",
    "dummy_annotations = np.concatenate((findAnnotations(87, category, train_annotations),findAnnotations(89, category, train_annotations)))\n",
    "bbox_train = getBoundingBoxesPictures(dummy_annotations, os.path.join(data_folder, path))\n",
    "\n",
    "'''\n",
    "categories_subset = [2,6,19,20,33,46,49,55]\n",
    "bbox = getBoundingBoxesPictures(findAnnotations(categories_subset[0], category, train_annotations),  os.path.join(data_folder, path))\n",
    "imgs = bbox[0]\n",
    "categories_subset.pop(0)\n",
    "labels = bbox[1]\n",
    "for category_id in categories_subset:\n",
    "    bbox = getBoundingBoxesPictures(findAnnotations(category_id, category, train_annotations),  os.path.join(data_folder, path))\n",
    "    imgs = np.concatenate((imgs,bbox[0]))\n",
    "    labels = np.concatenate((labels,bbox[1]))\n",
    "features = calculateFeatures(imgs)\n",
    "\n",
    "#splits = list(chunks(train_annotations, 20000))\n",
    "#labels, features = splitPreprocessing(splits, data_folder, path)\n",
    "print(\"[2,6,19,20,33,46,49,55]\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    features[0], labels, test_size=0.25, random_state=42)\n",
    "print(\"HOG\")\n",
    "svm = svmFit(x_train, y_train)\n",
    "#saveModel(svm, 'SVM_DAISY.sav')\n",
    "run.log('prediction', svmPredict(x_test, y_test, svm))\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "joblib.dump(value=svm, filename='outputs/SVM.pkl')\n",
    "joblib.dump(value=features, filename='outputs/features.npy')\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    features[1], labels, test_size=0.25, random_state=42)\n",
    "print(\"DAISY\")\n",
    "svm = svmFit(x_train, y_train)\n",
    "#saveModel(svm, 'SVM_DAISY.sav')\n",
    "run.log('prediction', svmPredict(x_test, y_test, svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./coco-multi-label/neural_network.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_folder/neural_network.py\n",
    "\n",
    "import argparse\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core import Run\n",
    "\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import os\n",
    "from PIL import Image, ImageFilter\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, Activation, Flatten, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from skimage.transform import resize\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "def loadAnnotations(fileLocation):\n",
    "    with open(fileLocation) as read_file:\n",
    "        annotations = json.load(read_file)\n",
    "    return annotations\n",
    "    \n",
    "def getBoundingBox(x,y,w,h,img):\n",
    "    return img[y:y+h,x:x+w]\n",
    "\n",
    "def findAnnotations(id, property, annotations):\n",
    "    items = []\n",
    "    for annotation in annotations: \n",
    "        if annotation[property] == id:\n",
    "            items.append(annotation)\n",
    "    return items\n",
    "\n",
    "def preProcessImage(img):\n",
    "    img = np.asarray(img)\n",
    "    return img\n",
    "\n",
    "def getBoundingBoxesPictures(annotations, path):\n",
    "    bounded_images = []\n",
    "    bounded_annotations = []\n",
    "    try:\n",
    "        for annotation in annotations:\n",
    "            image_id = annotation['image_id']\n",
    "            image_id_string = str(image_id).zfill(12)\n",
    "            image = Image.open(path + image_id_string +'.jpg').convert('RGB')\n",
    "            image = preProcessImage(image) \n",
    "            image_resized = resize(getBoundingBox(int(annotation['bbox'][0]),int(annotation['bbox'][1]),int(annotation['bbox'][2]),int(annotation['bbox'][3]),image)\n",
    "                                   , (48, 48),\n",
    "                           anti_aliasing=True)\n",
    "            bounded_images.append(image_resized)\n",
    "            bounded_annotations.append(annotation['category_id'])     \n",
    "    except Exception as ex:\n",
    "            print(ex)   \n",
    "    bounded_images = np.asarray(bounded_images)\n",
    "    bounded_annotations = np.asarray(bounded_annotations)\n",
    "    return bounded_images,bounded_annotations\n",
    "\n",
    " \n",
    "def constructCNN(conv_layer, layer_size, kernel_size, dense_size, dense_layer, dropout, num_classes, x_train):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(layer_size, (kernel_size, kernel_size), input_shape=x_train.shape[1:]))\n",
    "\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    for l in range(conv_layer-1):\n",
    "        model.add(Conv2D(layer_size, (kernel_size, kernel_size)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    if(dropout):\n",
    "        model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    for j in range(dense_layer):\n",
    "        model.add(Dense(dense_size))\n",
    "        model.add(Activation('relu'))\n",
    "    if(dropout):\n",
    "        model.add(Dropout(0.25))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data-folder', type=str, dest='data_folder', help='data folder mounting point')\n",
    "args = parser.parse_args()\n",
    "data_folder = os.path.join(args.data_folder, 'outputs')\n",
    "print('Data folder:', data_folder)\n",
    "run = Run.get_context()\n",
    "\n",
    "path = \"train2014/COCO_train2014_\"\n",
    "category = \"category_id\"\n",
    "x_train = joblib.load(os.path.join(data_folder, 'trainset2,6,19,20,33,46,49,55c.npy'))\n",
    "x_test = joblib.load(os.path.join(data_folder, 'testset2,6,19,20,33,46,49,55c.npy'))\n",
    "ylabels_train = joblib.load(os.path.join(data_folder, 'ylabels_train2,6,19,20,33,46,49,55.npy'))\n",
    "ylabels_test = joblib.load(os.path.join(data_folder, 'ylabels_test2,6,19,20,33,46,49,55.npy'))\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True, \n",
    "    featurewise_std_normalization=True,\n",
    "    zca_whitening=True,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "datagen.fit(x_train)\n",
    "datagen_test = ImageDataGenerator(featurewise_center=True, \n",
    "    featurewise_std_normalization=True,\n",
    "    zca_whitening=True,)\n",
    "datagen_test.fit(x_test)       \n",
    "\n",
    "sess = tf.Session()\n",
    "early_stopping_monitor = EarlyStopping(patience = 3)\n",
    "\n",
    "\n",
    "\n",
    "dense_layers = [3]\n",
    "layer_sizes = [64]\n",
    "dense_sizes = [64]\n",
    "conv_layers = [3]\n",
    "kernel_sizes = [3]\n",
    "for dense_layer in dense_layers:\n",
    "    for dense_size in dense_sizes:\n",
    "        for kernel_size in kernel_sizes:\n",
    "            for layer_size in layer_sizes:\n",
    "                for conv_layer in conv_layers:\n",
    "                    model = constructCNN(conv_layer, layer_size, kernel_size, dense_size, dense_layer, True, 8, x_train)\n",
    "                    NAME = \"{}-conv-{}-nodes-{}-dense-{}-dense_size-{}-kernel\".format(conv_layer, layer_size, dense_layer, dense_size, kernel_size)\n",
    "                    print(NAME)\n",
    "\n",
    "                    #model.fit(x_train, ylabels_train.astype(np.float32), batch_size=70, epochs=500, validation_data = (x_test, ylabels_test), callbacks = [early_stopping_monitor])\n",
    "                    model.fit_generator(datagen.flow(x_train, ylabels_train, batch_size=32,shuffle=True), \n",
    "                                        epochs=100, callbacks = [], validation_data = datagen_test.flow(x_test, ylabels_test, shuffle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./coco-multi-label\\\\utils.py'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "shutil.copy('utils.py', script_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "\n",
    "script_params = {\n",
    "    '--data-folder': ds.as_mount(),\n",
    "}\n",
    "\n",
    "'''\n",
    "est = Estimator(source_directory=script_folder,\n",
    "                script_params=script_params,\n",
    "                compute_target=compute_target,\n",
    "                entry_script='train.py',\n",
    "                conda_packages=['scikit-learn', 'scikit-image', 'pillow', 'opencv', 'numpy'])\n",
    "\n",
    "run = exp.submit(config=est)\n",
    "run\n",
    "'''\n",
    "\n",
    "keras_est = TensorFlow(source_directory=script_folder,\n",
    "                       script_params=script_params,\n",
    "                       compute_target=compute_target,\n",
    "                       entry_script='neural_network.py',\n",
    "                       pip_packages=['keras', 'scikit-learn', 'scikit-image', 'pillow'],\n",
    "                      use_gpu=True)\n",
    "\n",
    "run = exp.submit(config=keras_est)\n",
    "run\n",
    "\n",
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()\n",
    "\n",
    "run.wait_for_completion(show_output=True) # specify True for a verbose log\n",
    "\n",
    "print(run.get_metrics())\n",
    "\n",
    "print(run.get_file_names())\n",
    "\n",
    "# register model \n",
    "#model = run.register_model(model_name='svm_hog', model_path='outputs/svm_hog.pkl')\n",
    "#print(model.name, model.id, model.version, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi-class_classification_1553865295_69cd11d7 Running\n",
      "multi-class_classification_1553865088_1aa09112 Running\n",
      "multi-class_classification_1553864091_b5d7a8f0 Completed\n",
      "multi-class_classification_1553862335_1cc89eea Canceled\n",
      "multi-class_classification_1553861876_d7b23c93 Canceled\n",
      "multi-class_classification_1553861597_9c5e9bb1 Completed\n",
      "multi-class_classification_1553861290_d368a010 Canceled\n",
      "multi-class_classification_1553860670_3301962e Completed\n",
      "multi-class_classification_1553860550_0d3885a6 Completed\n",
      "multi-class_classification_1553860374_5df4ed84 Canceled\n",
      "multi-class_classification_1553860236_685bc22d Completed\n",
      "multi-class_classification_1553859814_0f6fbc92 Completed\n",
      "multi-class_classification_1553859524_df3f497b Completed\n",
      "multi-class_classification_1553858058_125fcfa9 Canceled\n",
      "multi-class_classification_1553856813_a97f9ba4 Completed\n",
      "multi-class_classification_1553782189_1323af86 Failed\n",
      "multi-class_classification_1553780005_dac75afb Completed\n",
      "multi-class_classification_1553776065_265e76df Completed\n",
      "multi-class_classification_1553773689_04db512d Completed\n",
      "multi-class_classification_1553769673_d8124539 Completed\n",
      "multi-class_classification_1553768855_ca077e98 Completed\n",
      "multi-class_classification_1553703167_373b390a Completed\n",
      "multi-class_classification_1553702959_2bcfcfcc Completed\n",
      "multi-class_classification_1553701648_0e3944cd Completed\n",
      "multi-class_classification_1553699147_bb7ab0af Completed\n",
      "multi-class_classification_1553684399_b8d38d12 Failed\n",
      "multi-class_classification_1553684351_214ddcc5 Failed\n",
      "multi-class_classification_1553684328_5223fe93 Failed\n",
      "multi-class_classification_1553684301_0f1b7a07 Failed\n",
      "multi-class_classification_1553684247_631465da Failed\n",
      "multi-class_classification_1553680811_a63e3996 Completed\n",
      "multi-class_classification_1553680723_dc27a926 Completed\n",
      "multi-class_classification_1553680785_cb723fb8 Completed\n",
      "multi-class_classification_1553680703_ac9a6f7e Failed\n",
      "multi-class_classification_1553680678_d80d0e43 Failed\n",
      "multi-class_classification_1553680289_0a4f12c5 Failed\n",
      "multi-class_classification_1553680273_c1b6f338 Failed\n",
      "multi-class_classification_1553680244_2365b1e8 Failed\n",
      "multi-class_classification_1553680209_fa1c3109 Failed\n",
      "multi-class_classification_1553680184_cc35c502 Failed\n",
      "multi-class_classification_1553678566_241caf36 Canceled\n",
      "multi-class_classification_1553678543_e4b4daef Canceled\n",
      "multi-class_classification_1553678494_d88bfaef Canceled\n",
      "multi-class_classification_1553678455_470e86ca Canceled\n",
      "multi-class_classification_1553603541_d88b74cf Failed\n",
      "multi-class_classification_1553602280_03bd512c Failed\n",
      "multi-class_classification_1553601454_c1c49a29 Completed\n",
      "multi-class_classification_1553601202_38ded359 Failed\n",
      "multi-class_classification_1553600706_192504e9 Failed\n",
      "multi-class_classification_1553600357_edcbbcf4 Failed\n",
      "multi-class_classification_1552395260_ff63f595 Failed\n",
      "multi-class_classification_1552391966_9ecf5536 Failed\n",
      "multi-class_classification_1552390657_a670c821 Canceled\n",
      "multi-class_classification_1552234611_d13aa31f Completed\n",
      "multi-class_classification_1552234551_7c1e71ae Canceled\n",
      "multi-class_classification_1552234466_f3214ec7 Canceled\n",
      "multi-class_classification_1552038452_136e0004 Completed\n",
      "multi-class_classification_1552036395_7b0babc0 Failed\n",
      "multi-class_classification_1551993792_0043c68d Completed\n",
      "multi-class_classification_1551969804_85939a1c Completed\n",
      "multi-class_classification_1551962256_a1ed3440 Completed\n",
      "multi-class_classification_1551960911_4643c688 Failed\n",
      "multi-class_classification_1551887435_7124151d Failed\n",
      "multi-class_classification_1551886465_accda2c9 Failed\n",
      "multi-class_classification_1551885264_4194f72c Failed\n",
      "multi-class_classification_1551884797_0567f791 Failed\n",
      "multi-class_classification_1551884025_3c1ff795 Completed\n",
      "multi-class_classification_1551883969_fdf5defa Failed\n",
      "multi-class_classification_1551883826_304b1f1c Failed\n",
      "multi-class_classification_1551883612_e3e085d7 Completed\n",
      "multi-class_classification_1551883318_50e62188 Failed\n",
      "multi-class_classification_1551882973_6dee408f Failed\n",
      "multi-class_classification_1551882770_f76db873 Failed\n",
      "multi-class_classification_1551881518_a9151cc0 Failed\n",
      "multi-class_classification_1551881317_32dcae3d Failed\n",
      "multi-class_classification_1551881269_c1302161 Failed\n",
      "multi-class_classification_1551880945_de540ad8 Failed\n",
      "multi-class_classification_1551880448_86941086 Failed\n",
      "multi-class_classification_1551879274_0f876078 Failed\n",
      "multi-class_classification_1551879435_144caf8e Failed\n",
      "multi-class_classification_1551876853_03ef5c6b Failed\n",
      "multi-class_classification_1551872752_6b1a89a8 Failed\n",
      "multi-class_classification_1551803937_c7d9cf5f Failed\n",
      "multi-class_classification_1551801159_b8d14162 Failed\n",
      "multi-class_classification_1551799624_6dd5ca3d Failed\n",
      "multi-class_classification_1551799639_42f70fb0 Failed\n",
      "multi-class_classification_1551798408_6db7d8bd Failed\n",
      "multi-class_classification_1551798203_a7355bea Failed\n",
      "multi-class_classification_1551796860_b64b350c Failed\n",
      "multi-class_classification_1551358822_ea0feadc Failed\n",
      "multi-class_classification_1551312309_efbc9894 Failed\n",
      "multi-class_classification_1551312289_e8288cf8 Failed\n",
      "multi-class_classification_1551312260_973a285b Completed\n",
      "multi-class_classification_1551306089_efebafc8 Completed\n",
      "multi-class_classification_1551278785_10c7deeb Completed\n",
      "multi-class_classification_1551277843_5902f6cc Failed\n",
      "multi-class_classification_1551277818_db8ff661 Failed\n",
      "multi-class_classification_1551274041_6b2cab57 Failed\n",
      "multi-class_classification_1551268693_ad9243ca Failed\n",
      "multi-class_classification_1551259674_009fc1ff Failed\n",
      "multi-class_classification_1551197057_bf9371f6 Failed\n",
      "multi-class_classification_1551196530_93f4b7e9 Completed\n",
      "multi-class_classification_1551196174_507f0811 Failed\n",
      "multi-class_classification_1551193829_480640bd Failed\n",
      "multi-class_classification_1551188169_b8a42b31 Failed\n",
      "multi-class_classification_1551187122_3cc3e30e Failed\n",
      "multi-class_classification_1551186176_c2e8b5cc Failed\n",
      "multi-class_classification_1551182579_65e73c2a Failed\n",
      "multi-class_classification_1551179111_2341d45b Failed\n",
      "multi-class_classification_1553865385_99d5c49e Queued\n",
      "multi-class_classification_1551876359_660a7dd0 Failed\n",
      "multi-class_classification_1551876014_d5ee614d Failed\n",
      "multi-class_classification_1551875603_7f672612 Failed\n",
      "multi-class_classification_1551875121_8fbc6a46 Failed\n",
      "multi-class_classification_1551874568_62529c55 Failed\n",
      "multi-class_classification_1551873997_a7b9da22 Failed\n",
      "multi-class_classification_1551803129_6cdf5e0c Failed\n",
      "<class 'azureml.core.script_run.ScriptRun'> Failed\n"
     ]
    }
   ],
   "source": [
    "for r in exp.get_runs():  \n",
    "    print(r.id, r.get_status())\n",
    "    if r.get_status() not in ['Complete', 'Failed']:\n",
    "        r.cancel()\n",
    "\n",
    "# if you know the run id, you can \"rehydrate\" the run\n",
    "from azureml.core import get_run\n",
    "#r = get_run(experiment=exp, run_id=\"multi-class_classification_1552234551_7c1e71ae\", rehydrate=True)\n",
    "# check the returned run type and status\n",
    "print(type(r), r.get_status())\n",
    "\n",
    "# you can cancel a run if it hasn't completed or failed\n",
    "#if r.get_status() not in ['Complete', 'Failed']:\n",
    "    #r.cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gray_img = rgb2gray(image)\n",
    "color = ('b','g','r')\n",
    "plt.figure()\n",
    "for i,col in enumerate(color):\n",
    "    histr = cv2.calcHist([image],[i],None,[256],[0,256])\n",
    "    plt.plot(histr,color = col)\n",
    "    plt.xlim([0,256])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()\n",
    "#print(x_train[0:9].values)\n",
    "#print(y_train[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(features[0][0])\n",
    "#print(features[1])\n",
    "'''\n",
    "fig, ax = plt.subplots(1, figsize=(8, 4))\n",
    "\n",
    "hog_image_rescaled = exposure.rescale_intensity(features[0][0][1], in_range=(0, 10))\n",
    "\n",
    "ax.axis('off')\n",
    "ax.imshow(hog_image_rescaled, cmap=plt.cm.gray)\n",
    "ax.set_title('Histogram of Oriented Gradients')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "blobs_log = blob_log(gray_img, max_sigma=30, num_sigma=10, threshold=.1)\n",
    "\n",
    "blobs_log[:, 2] = blobs_log[:, 2] * sqrt(2)\n",
    "\n",
    "blobs_dog = blob_dog(gray_img, max_sigma=30, threshold=.1)\n",
    "blobs_dog[:, 2] = blobs_dog[:, 2] * sqrt(2)\n",
    "\n",
    "blobs_doh = blob_doh(gray_img, max_sigma=30, threshold=.01)\n",
    "\n",
    "blobs_list = [blobs_log, blobs_dog, blobs_doh]\n",
    "colors = ['yellow', 'lime', 'red']\n",
    "titles = ['Laplacian of Gaussian', 'Difference of Gaussian',\n",
    "          'Determinant of Hessian']\n",
    "sequence = zip(blobs_list, colors, titles)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(9, 3), sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "\n",
    "for idx, (blobs, color, title) in enumerate(sequence):\n",
    "    ax[idx].set_title(title)\n",
    "    ax[idx].imshow(image, interpolation='nearest')\n",
    "    for blob in blobs:\n",
    "        y, x, r = blob\n",
    "        c = plt.Circle((x, y), r, color=color, linewidth=2, fill=False)\n",
    "        ax[idx].add_patch(c)\n",
    "    ax[idx].set_axis_off()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "fd, hog_image = hog(image, orientations=8, pixels_per_cell=(16, 16),\n",
    "                    cells_per_block=(1, 1), visualize=True, multichannel=True)\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(8, 4))\n",
    "\n",
    "hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
    "\n",
    "ax.axis('off')\n",
    "ax.imshow(hog_image_rescaled, cmap=plt.cm.gray)\n",
    "ax.set_title('Histogram of Oriented Gradients')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "print(gray_img)\n",
    "coords = corner_peaks(corner_harris(gray_img), min_distance=5)\n",
    "\n",
    "fig, (ax) = plt.subplots(1, figsize=(8, 4))\n",
    "\n",
    "ax.axis('off')\n",
    "ax.imshow(image)\n",
    "ax.plot(coords[:, 1], coords[:, 0], 'or', ms=4)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "kp = sift.detect(gray,None)\n",
    "\n",
    "siftimg=cv2.drawKeypoints(gray,kp,img)\n",
    "plt.figure()\n",
    "plt.axis('off')\n",
    "plt.imshow(siftimg)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
